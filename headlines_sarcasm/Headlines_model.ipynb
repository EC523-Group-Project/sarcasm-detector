{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6w1r6UJfKFp"
   },
   "source": [
    "# Hyper-Paremeter testing, training, and final model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNXyrz9wcv2Z"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "except ImportError as e:\n",
    "    print('transformers not installed')\n",
    "    print('Installing now...')\n",
    "    !pip install -q git+https://github.com/huggingface/transformers.git\n",
    "    pass  \n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "except ImportError as e:\n",
    "    print('optuna not installed')\n",
    "    print('Installing now...')\n",
    "    !pip install optuna\n",
    "    pass  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKMAuh9oczDj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import io \n",
    "import os\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import transformers\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers.utils.dummy_pt_objects import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForTokenClassification,AutoConfig, AutoModel,AutoTokenizer,BertModel,BertConfig,AdamW, get_constant_schedule,BertForSequenceClassification,get_linear_schedule_with_warmup,get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "\n",
    "#Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvnurzgWc0W4"
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab == True:\n",
    "    #Mounting Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    \n",
    "    %cd '/content/gdrive/Shareddrives/523 Project/Data/News Headlines'\n",
    "    %ls\n",
    "else:\n",
    "    MODEL_PATH = '/projectnb/dl523/projects/Sarcasm/Sarcasm_Models/sarcasm_bert_headline.pth'\n",
    "    DATA_DIR = '/projectnb2/dl523/projects/Sarcasm'\n",
    "    os.chdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8i9XMHhc3xY"
   },
   "outputs": [],
   "source": [
    "#Getting the BERT outputs for use with other downstream model implementations \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data\n",
    "df = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\",lines = True)\n",
    "df = df.rename(columns={'is_sarcastic': 'label'})\n",
    "df = df.drop('article_link', 1)\n",
    "df.head()\n",
    "\n",
    "#splits for training test validation\n",
    "\n",
    "train_headlines, temporary_text, train_label, temporary_label = train_test_split(df['headline'], df['label'], \n",
    "                                                                    random_state=200, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "validation_headlines, test_headlines, validation_label, test_label = train_test_split(temporary_text, temporary_label, \n",
    "                                                                    random_state=200, \n",
    "                                                                    test_size=0.5, \n",
    "                                                                    stratify=temporary_label)\n",
    "\n",
    "\n",
    "#Set max length for the padding/clipping\n",
    "count = df['headline'].str.split().str.len()\n",
    "count.describe()\n",
    "\n",
    "max_length = 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for modifying BERT \n",
    "class bert_for_sarcasm(nn.Module):\n",
    "\n",
    "    def __init__(self,input_model, linear1 = 256,linear2 = 128,drop = .25,mod_type = 'binary',bert_model = 'bert-base-uncased'):\n",
    "        super(bert_for_sarcasm,self).__init__()\n",
    "        # Assumes size parameters of bert-base-uncased\n",
    "        self.mod_type = mod_type\n",
    "        self.bert_model = bert_model\n",
    "        if self.bert_model == 'bert-base-uncased':\n",
    "            self.model_size = 768\n",
    "        else:\n",
    "            self.model_size = 1024\n",
    "        self.input_model = input_model\n",
    "        \n",
    "        self.linear = nn.Linear(self.model_size,linear1)\n",
    "        \n",
    "        self.linear2 = nn.Linear(linear1,linear2)\n",
    "        \n",
    "        self.linear3 = nn.Linear(linear2,2)\n",
    "        \n",
    "        self.linear3_binary = nn.Linear(linear2,1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.log = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    def forward(self,input_values,attention_mask):\n",
    "   \n",
    "        _,output = self.input_model(input_values, attention_mask=attention_mask).values()\n",
    "        \n",
    "        output = self.linear(output)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        output = self.relu(output)\n",
    "        \n",
    "        output = self.linear2(output)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        output = self.relu(output)\n",
    "        \n",
    "        if self.mod_type == 'binary':\n",
    "            output = self.linear3_binary(output)\n",
    "            output = self.sigmoid(output)\n",
    "        else:\n",
    "            output = self.linear3(output)\n",
    "            output = self.log(output)\n",
    "\n",
    "        \n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmnqPuWudBPa"
   },
   "outputs": [],
   "source": [
    "# Finding best hyper-parameters\n",
    "def train_bert(model, params,trial,tokenizer):\n",
    "    model.to(device)\n",
    "    max_length = 35\n",
    "\n",
    "    #Create tokenized training, validation, and test splits\n",
    "\n",
    "    training_tokens = tokenizer.batch_encode_plus(train_headlines.tolist(),max_length = max_length,padding = True,truncation = True)\n",
    "    validation_tokens = tokenizer.batch_encode_plus(validation_headlines.tolist(),max_length = max_length,padding = True,truncation = True)\n",
    "    test_tokens = tokenizer.batch_encode_plus(test_headlines.tolist(),max_length = max_length,padding= True,truncation = True)\n",
    "\n",
    "    #Stacking the inputs as tensors for use in the BERT model\n",
    "\n",
    "    training_set = TensorDataset(torch.tensor(training_tokens['input_ids']),torch.tensor(training_tokens['attention_mask']),torch.tensor(train_label.tolist()))\n",
    "    validation_set = TensorDataset(torch.tensor(validation_tokens['input_ids']),torch.tensor(validation_tokens['attention_mask']),torch.tensor(validation_label.tolist()))\n",
    "    test_set = TensorDataset(torch.tensor(test_tokens['input_ids']),torch.tensor(test_tokens['attention_mask']),torch.tensor(test_label.tolist()))\n",
    "\n",
    "    trainloader = DataLoader(training_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "    validationloader = DataLoader(validation_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "    testloader = DataLoader(test_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "\n",
    "    Epochs = 60\n",
    "\n",
    "    \n",
    "    #optimizer and scheduler for learning rate\n",
    "    optimizer = AdamW(model.parameters(),lr = params[\"lr\"],eps = 1e-6)\n",
    "    NO_SCHEDULER = False\n",
    "    if params['schedule'] == \"linear\":\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 2,num_training_steps = len(trainloader)*Epochs)\n",
    "    elif params['schedule'] == 'cosine':\n",
    "        scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer,num_warmup_steps = 2, num_training_steps = len(trainloader)*Epochs)\n",
    "    else:\n",
    "        NO_SCHEDULER = True\n",
    "        pass\n",
    "    # Setting the correct loss function \n",
    "    if params['mod_type'] == 'binary':\n",
    "        loss_function = nn.BCELoss()\n",
    "        BINARY = True\n",
    "    else:\n",
    "        loss_function = nn.NLLLoss()\n",
    "        BINARY = False\n",
    "    \n",
    "    min_validation_loss = np.inf\n",
    "    total = 0 \n",
    "    correct = 0\n",
    "    for epoch in range(1, Epochs+1):\n",
    "        model.train()\n",
    "        training_loss = 0 \n",
    "        epoch_step = 0\n",
    "        for idx, (inputs,attention_mask,label) in enumerate(trainloader):\n",
    "\n",
    "            inputs,attention_mask,label = inputs.to(device),attention_mask.to(device),label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(inputs,attention_mask)\n",
    "            if BINARY:\n",
    "                output = torch.flatten(output)\n",
    "                loss = loss_function(output,label.float())\n",
    "            else:\n",
    "                loss = loss_function(output,label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss +=loss.item()*inputs.size(0)\n",
    "            \n",
    "        if NO_SCHEDULER == False:\n",
    "            scheduler.step()\n",
    "        \n",
    "        validation_loss = 0\n",
    "        \n",
    "        total_acc_val = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (inputs,attention_mask,label) in enumerate(validationloader):\n",
    "                inputs,attention_mask,label = inputs.to(device),attention_mask.to(device),label.to(device)\n",
    "\n",
    "                output = model(inputs,attention_mask)\n",
    "                \n",
    "                if BINARY:\n",
    "                    output = torch.flatten(output)\n",
    "                    loss = loss_function(output,label.float())\n",
    "                else:\n",
    "                    loss = loss_function(output,label)\n",
    "\n",
    "                \n",
    "                validation_loss += loss.item()*inputs.size(0)\n",
    "                if BINARY:\n",
    "                    output[output<0.5] = 0\n",
    "                    output[output>=0.5] = 1\n",
    "                    correct = (output == label).float().sum().item()\n",
    "                    total_acc_val += correct\n",
    "                else:\n",
    "                    correct = (output.argmax(dim=1) == label).sum().item()\n",
    "                    total_acc_val += correct\n",
    "                \n",
    "        # If the training is doing worse then a median set, stop training to save time\n",
    "        prune_check = total_acc_val/len(validation_set)       \n",
    "        trial.report(prune_check, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "          raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return total_acc_val/len(validation_set)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params):\n",
    "    bertconfig = BertConfig()\n",
    "    tokenizer2 = AutoTokenizer.from_pretrained(params['bert_model'])\n",
    "\n",
    "    bert2 = BertModel.from_pretrained(params['bert_model'])\n",
    "    \n",
    "    #Only want to train the additional layers at first,freezing pretrained\n",
    "    for param in bert2.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for idx,param in enumerate(bert2.encoder.layer):\n",
    "        if 1+idx>len(bert2.encoder.layer)-params['number_to_unfreeze']:\n",
    "            param.requires_grad = True\n",
    "        bert2.pooler.requires_grad = True\n",
    "\n",
    "\n",
    "    return bert_for_sarcasm(bert2,params['linear1'],params['linear2'],params['drop'],params['mod_type'],params['bert_model']),tokenizer2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for hyper-parameter testing\n",
    "def objective(trial):\n",
    "    # Set of hyper-parameters we are interested in analyzing\n",
    "    params = {\n",
    "        'lr':trial.suggest_categorical('lr',[1e-5,1e-4,1e-3]),\n",
    "        'linear1': trial.suggest_categorical('linear1',[256,512]),\n",
    "        'linear2': trial.suggest_categorical('linear2',[64,128]),\n",
    "        'drop': trial.suggest_categorical(\"drop\",[0,.1,.2]),\n",
    "        'batch_size': trial.suggest_categorical('batch_size',[32,64,128]),\n",
    "        'schedule': trial.suggest_categorical('schedule',['none','cosine','linear']),\n",
    "        'bert_model': trial.suggest_categorical('bert_model',['bert-base-uncased','bert-large-uncased']),\n",
    "        'mod_type': trial.suggest_categorical('mod_type',['binary','multi']), # binary or multi\n",
    "        'number_to_unfreeze': trial.suggest_categorical('number_to_unfreeze',[0,1,2,4,6,12])\n",
    "    }\n",
    "    \n",
    "    \n",
    "    model,tokenizer = build_model(params)\n",
    "    \n",
    "    accuracy = train_bert(model,params,trial,tokenizer)\n",
    "    \n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRkBO-CHdJkx"
   },
   "outputs": [],
   "source": [
    "def optimal_values(study):\n",
    "    # Return the optimal values from the hyper-parameter testing\n",
    "    \n",
    "    best_trial = study.best_trial\n",
    "    best_parameters = best_trial.params\n",
    "    return best_parameters\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9thujkkndLAL"
   },
   "outputs": [],
   "source": [
    "# Training after hyper-parameter testing\n",
    "def train_optimized_bert(model,params,tokenizer,Epochs):\n",
    "   \n",
    "    model.to(device)\n",
    "    #Set max length for the padding/clipping\n",
    "    max_length = 35\n",
    "    #Create tokenized training, validation, and test splits\n",
    "\n",
    "    training_tokens = tokenizer.batch_encode_plus(train_headlines.tolist(),max_length = max_length,padding = True,truncation = True)\n",
    "    validation_tokens = tokenizer.batch_encode_plus(validation_headlines.tolist(),max_length = max_length,padding = True,truncation = True)\n",
    "    test_tokens = tokenizer.batch_encode_plus(test_headlines.tolist(),max_length = max_length,padding= True,truncation = True)\n",
    "\n",
    "    #Stacking the inputs as tensors for use in the BERT model\n",
    "\n",
    "    training_set = TensorDataset(torch.tensor(training_tokens['input_ids']),torch.tensor(training_tokens['attention_mask']),torch.tensor(train_label.tolist()))\n",
    "    validation_set = TensorDataset(torch.tensor(validation_tokens['input_ids']),torch.tensor(validation_tokens['attention_mask']),torch.tensor(validation_label.tolist()))\n",
    "    test_set = TensorDataset(torch.tensor(test_tokens['input_ids']),torch.tensor(test_tokens['attention_mask']),torch.tensor(test_label.tolist()))\n",
    "\n",
    "    # Data loaders \n",
    "    trainloader = DataLoader(training_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "    validationloader = DataLoader(validation_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "    testloader = DataLoader(test_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "\n",
    "\n",
    "    optimizer = AdamW(model.parameters(),lr = params[\"lr\"],eps = 1e-6)\n",
    "    NO_SCHEDULER = False\n",
    "    if params['schedule'] == \"linear\":\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 2,num_training_steps = len(trainloader)*Epochs)\n",
    "    elif params['schedule'] == 'cosine':\n",
    "        scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer,num_warmup_steps = 2, num_training_steps = len(trainloader)*Epochs)\n",
    "    else:\n",
    "        NO_SCHEDULER = True\n",
    "        \n",
    "        \n",
    "    if params['mod_type'] == 'binary':\n",
    "        loss_function = nn.BCELoss()\n",
    "        BINARY = True\n",
    "    else:\n",
    "        loss_function = nn.NLLLoss()\n",
    "        BINARY = False\n",
    "        \n",
    "    # For checking early stop criteria\n",
    "    min_validation_loss = np.inf\n",
    "    patience = 3\n",
    "    stop_number = 0\n",
    "    epoch_count = 0\n",
    "    running_validation_loss = []\n",
    "    running_training_loss = []\n",
    "    validation_acc = []\n",
    "    training_acc = []\n",
    "    \n",
    "    last_loss = np.inf\n",
    "    for epoch in range(1, Epochs+1):\n",
    "        epoch_count+=1\n",
    "        print('Epoch',epoch_count)\n",
    "        model.train()\n",
    "        training_loss = 0 \n",
    "\n",
    "        train_correct = 0 \n",
    "        total_acc_train = 0\n",
    "        for idx, (inputs,attention_mask,label) in enumerate(tqdm(trainloader,total = len(trainloader))):\n",
    "\n",
    "            inputs,attention_mask,label = inputs.to(device),attention_mask.to(device),label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(inputs,attention_mask)\n",
    "            \n",
    "            if BINARY:\n",
    "                output = torch.flatten(output)\n",
    "                loss = loss_function(output,label.float())\n",
    "            else:\n",
    "                loss = loss_function(output,label)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss +=loss.item()*inputs.size(0)\n",
    "\n",
    "            \n",
    "            if BINARY:\n",
    "                output[output<0.5] = 0\n",
    "                output[output>=0.5] = 1\n",
    "                train_correct = (output == label).float().sum().item()\n",
    "                total_acc_train += train_correct\n",
    "            else:\n",
    "                train_correct = (output.argmax(dim=1) == label).sum().item()\n",
    "                total_acc_train += train_correct\n",
    "\n",
    "        if NO_SCHEDULER == False:\n",
    "            scheduler.step()\n",
    "\n",
    "    \n",
    "        validation_loss = 0\n",
    "\n",
    "        total_acc_val = 0\n",
    "        val_correct = 0 \n",
    "      \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (inputs,attention_mask,label) in enumerate(tqdm(validationloader,total = len(validationloader))):\n",
    "                inputs,attention_mask,label = inputs.to(device),attention_mask.to(device),label.to(device)\n",
    "\n",
    "                output = model(inputs,attention_mask)\n",
    "                \n",
    "                if BINARY:\n",
    "                    output = torch.flatten(output)\n",
    "                    loss = loss_function(output,label.float())\n",
    "                else:\n",
    "                    loss = loss_function(output,label)\n",
    "                    \n",
    "                validation_loss += loss.item()*inputs.size(0)\n",
    "                \n",
    "                if BINARY:\n",
    "                    output[output<0.5] = 0\n",
    "                    output[output>=0.5] = 1\n",
    "                    val_correct = (output == label).float().sum().item()\n",
    "                    total_acc_val += val_correct\n",
    "                else:\n",
    "                    val_correct = (output.argmax(dim=1) == label).sum().item()\n",
    "                    total_acc_val += val_correct\n",
    "\n",
    "        #Early Stopping Criteria\n",
    "    \n",
    "        if validation_loss>= last_loss:\n",
    "            stop_number+=1\n",
    "            if stop_number >= patience:\n",
    "                return model,running_training_loss,training_acc,running_validation_loss,validation_acc,epoch_count,testloader\n",
    "        else:\n",
    "            stop_number = 0\n",
    "            if validation_loss< min_validation_loss:\n",
    "                min_validation_loss = validation_loss\n",
    "                #Save the best performing model parameters \n",
    "                torch.save(model, MODEL_PATH)\n",
    "        last_loss = validation_loss\n",
    "\n",
    "        # For graphing training and testing loss, accuracy\n",
    "        running_validation_loss.append(validation_loss/len(validation_set))\n",
    "        running_training_loss.append(training_loss/len(training_set))\n",
    "\n",
    "        validation_acc.append(total_acc_val/len(validation_set))\n",
    "        training_acc.append(total_acc_train/len(training_set))\n",
    "\n",
    "    return model,running_training_loss,training_acc,running_validation_loss,validation_acc,epoch_count,testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzPYLhl_dPBu"
   },
   "outputs": [],
   "source": [
    "# Final Model Testing\n",
    "def test_bert(model,testloader):\n",
    "    correct = []\n",
    "    final_pred = []\n",
    "    final_lab = []\n",
    "    model.eval()\n",
    "    \n",
    "    # For selecting correct loss function, properly working with the outputs\n",
    "    if model.mod_type == 'binary':\n",
    "        BINARY = True\n",
    "    else:\n",
    "        BINARY = False\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs,attention_mask,label) in enumerate(tqdm(testloader,total = len(testloader))):\n",
    "            inputs,attention_mask,label = inputs.to(device),attention_mask.to(device), label.to(device)\n",
    "            output = model(inputs,attention_mask).cpu()\n",
    "            if BINARY:\n",
    "                output = torch.flatten(output)\n",
    "                output[output<0.5] = 0\n",
    "                output[output>=0.5] = 1\n",
    "                final_lab.extend(label.cpu().numpy())\n",
    "                final_pred.extend(output.numpy())\n",
    "            else:\n",
    "                preds = output.data.max(1, keepdim=True)[1].squeeze(1).numpy()\n",
    "\n",
    "                l = label.cpu().numpy()\n",
    "                comp = l == preds\n",
    "                final_lab.extend(l)\n",
    "                final_pred.extend(preds)\n",
    "\n",
    "    return final_lab,final_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for working with reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slighlty modified test function to account for different structure of reddit data\n",
    "def test_bert_reddit(model,testloader):\n",
    "    correct = []\n",
    "    final_pred = []\n",
    "    final_lab = []\n",
    "    model.eval()\n",
    "    \n",
    "    # For selecting correct loss function, properly working with the outputs\n",
    "    if model.mod_type == 'binary':\n",
    "        BINARY = True\n",
    "    else:\n",
    "        BINARY = False\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (encodings,label) in enumerate(tqdm(testloader,total = len(testloader))):\n",
    "            inputs = encodings['input_ids']\n",
    "            attention_mask = encodings['attention_mask']\n",
    "            inputs,attention_mask,label = inputs.to(device),attention_mask.to(device), label.to(device)\n",
    "            output = model(inputs,attention_mask).cpu()\n",
    "            if BINARY:\n",
    "                output = torch.flatten(output)\n",
    "                output[output<0.5] = 0\n",
    "                output[output>=0.5] = 1\n",
    "                final_lab.extend(label.cpu().numpy())\n",
    "                final_pred.extend(output.numpy())\n",
    "            else:\n",
    "                preds = output.data.max(1, keepdim=True)[1].squeeze(1).numpy()\n",
    "\n",
    "                l = label.cpu().numpy()\n",
    "                comp = l == preds\n",
    "                final_lab.extend(l)\n",
    "                final_pred.extend(preds)\n",
    "\n",
    "    return final_lab,final_pred\n",
    "\n",
    "class Reddit(Dataset):\n",
    "    def __init__(self, pd_text, pd_labels, selected_tokenizer, max_length=None):\n",
    "        \n",
    "       \n",
    "        self.inputs = selected_tokenizer.batch_encode_plus(pd_text.tolist(), max_length = max_length,\\\n",
    "                                                          padding = True, truncation = True, \\\n",
    "                                                         add_special_tokens = True, return_tensors = \"pt\", \\\n",
    "                                                          return_attention_mask = True)\n",
    "        \n",
    "        self.labels = torch.Tensor(pd_labels.tolist())\n",
    "        return\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.labels)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self,item):\n",
    "        text = {key: self.inputs[key][item] for key in self.inputs.keys()}\n",
    "        label = self.labels[item]\n",
    "        return text, label\n",
    "    \n",
    "\n",
    "def split_reddit_data(csv_path):\n",
    "    \"\"\"\n",
    "        Reads in reddit data from .csv and performs a stratified split into training-validation-testing sets   \n",
    "    \"\"\"\n",
    "    #read in .csv\n",
    "    data_all = None\n",
    "    try:\n",
    "        data_all = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError as e:\n",
    "        print('Data csv not found')\n",
    "        return\n",
    "    \n",
    "    #some NA in data (see data EDA file)\n",
    "    data_all.dropna(subset=['comment'], inplace=True)\n",
    "    \n",
    "    x_train, x_testval, y_train, y_testval= train_test_split(data_all['comment'], data_all['label'], random_state=200, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=data_all['label'])\n",
    "    \n",
    "    x_test, x_val, y_test, y_val = train_test_split(x_testval, y_testval, random_state=200, \n",
    "                                                                    test_size=0.5, \n",
    "                                                                    stratify=y_testval)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test \n",
    "\n",
    "\n",
    "def get_data_loaders(train, val, test, batch_size, num_workers):\n",
    "    \n",
    "    trainloader = DataLoader(train, batch_size = batch_size,num_workers=num_workers,shuffle = True)\n",
    "    validationloader = DataLoader(val, batch_size = batch_size,num_workers=num_workers,shuffle = True)\n",
    "    testloader = DataLoader(test, batch_size = batch_size,num_workers=num_workers,shuffle = True)\n",
    "    \n",
    "    return trainloader, validationloader, testloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running all functions to find and evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AZB4Bgad-d3"
   },
   "outputs": [],
   "source": [
    "# Create and train final model \n",
    "\n",
    "# Find Best Hyper-Parameters\n",
    "Epochs = 150 # Training epochs for the best performing model from hyper-parameter testing\n",
    "n_trials = 100 # Number of combinations of hyper-parameters to test \n",
    "n_jobs = 1 # Number of parallel trials \n",
    "study = optuna.create_study(direction=\"maximize\",\n",
    "                            sampler=optuna.samplers.TPESampler(),\n",
    "                            pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_jobs = n_jobs,n_trials=n_trials,show_progress_bar = True)\n",
    "\n",
    "# Plots to visualize the hyper-paremeter search \n",
    "plot_optimization_history(study);\n",
    "plot_param_importances(study);\n",
    "\n",
    "# Getting best parameters to train final model\n",
    "\n",
    "best_parameters = optimal_values(study)\n",
    "print('Best Values:')\n",
    "for key, value in best_parameters.items():\n",
    "    print(key, ' : ', value)\n",
    "final_model,tokenizer = build_model(best_parameters)\n",
    "\n",
    "# Training the final model \n",
    "trained_final_model,train_loss,train_acc,val_loss,val_acc,epoch_count,testloader = train_optimized_bert(final_model,best_parameters,tokenizer,Epochs)\n",
    "\n",
    "# Training and Validation Loss Plots\n",
    "plt.plot(train_loss,'g',label = 'Training Loss')\n",
    "plt.plot(val_loss,'r',label = 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Training and Validation Accuracy Plots\n",
    "plt.plot(val_acc,'g',label = 'Training Accuracy')\n",
    "plt.plot(train_acc,'r',label = 'Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Testing Final Model\n",
    "final_lab,final_pred = test_bert(trained_final_model,testloader)\n",
    "\n",
    "# Visualizing the results\n",
    "conf_mat = confusion_matrix(final_lab, final_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "plt.title('Confusion Matrix For Sarcasm_BERT')\n",
    "disp.plot(ax = ax)\n",
    "\n",
    "r_words = [\"Sarcastic\",\"Not Sarcastic\"]\n",
    "class_report = classification_report(final_lab,final_pred,target_names =r_words)\n",
    "print('\\033[1m'+'Precision, Recall and Accuracy for Headline Data:\\n')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7298tFreAKc"
   },
   "outputs": [],
   "source": [
    "# Looking at the tokenizer and its output\n",
    "\n",
    "new = tokenizer(\"Smartest Man In World Dead After Papercut\",return_tensors=\"pt\")\n",
    "new.to(device)\n",
    "print(new)\n",
    "outputs = trained_final_model(new['input_ids'],new['attention_mask']).detach().cpu()\n",
    "print(np.exp(outputs))\n",
    "a = outputs.data.max(1, keepdim=True)[1].squeeze(1).numpy()\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCoFPKMPeDTv"
   },
   "source": [
    "## Testing Headlines Model on Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the reddit data foor testing on the model trained on headlines data\n",
    "csv_path = '/projectnb/dl523/projects/Sarcasm/train-balanced-sarcasm.csv'\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = split_reddit_data(csv_path)\n",
    "\n",
    "max_length = 35\n",
    "reddit_train = Reddit(x_train, y_train, tokenizer, max_length)\n",
    "reddit_val = Reddit(x_val, y_val, tokenizer, max_length)\n",
    "reddit_test = Reddit(x_test, y_test, tokenizer, max_length)\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "trainloader_r, validationloader_r, testloader_r = get_data_loaders(reddit_train, reddit_val, reddit_test, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best headlines model \n",
    "\n",
    "model = torch.load(MODEL_PATH)\n",
    "\n",
    "# testing\n",
    "model.to(device)\n",
    "final_lab_r,final_pred_r = test_bert_reddit(model,testloader_r)\n",
    "\n",
    "# Visualizing the results\n",
    "conf_mat = confusion_matrix(final_lab_r, final_pred_r)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "plt.title('Confusion Matrix For Sarcasm_BERT')\n",
    "disp.plot(ax = ax)\n",
    "\n",
    "r_words = [\"Sarcastic\",\"Not Sarcastic\"]\n",
    "class_report = classification_report(final_lab_r,final_pred_r,target_names =r_words)\n",
    "print('\\033[1m'+'Precision, Recall and Accuracy for Reddit Data:\\n')\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Headlines_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
