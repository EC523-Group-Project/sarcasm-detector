{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test running pretrained BERT on reddit data\n",
    "- Maybe start adding multi level attention blocks at the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "except ImportError as e:\n",
    "    print('transformers not installed')\n",
    "    print('Installing now...')\n",
    "    !pip install -q git+https://github.com/huggingface/transformers.git\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reddit_bert_functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import transformers\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers.utils.dummy_pt_objects import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForTokenClassification,AutoConfig, AutoModel,AutoTokenizer,BertModel,BertConfig,AdamW, get_constant_schedule,BertForSequenceClassification,get_linear_schedule_with_warmup\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import reddit dataset, split and create PyTorch data class objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'train-balanced-sarcasm.csv'\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = fun.split_reddit_data(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count per each sample\n",
    "count = x_train.str.split().str.len()\n",
    "plt.hist(count, bins=30, range=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if even split between labels\n",
    "import seaborn as sns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 7))\n",
    "fig.suptitle('Distribution of Classes Reddit\\n0:Non-Sarcastic vs. 1:Sarcastic accross data splits')\n",
    "sns.countplot(ax=axes[0], x=y_train)\n",
    "axes[0].set_title('Training Set')\n",
    "sns.countplot(ax=axes[1], x=y_val)\n",
    "axes[1].set_title('Validation Set')\n",
    "sns.countplot(ax=axes[2], x=y_test)\n",
    "axes[2].set_title('Test Set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 35  #based on word count bar plot above, 35 is reasonable\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "reddit_train = fun.Reddit(x_train, y_train, tokenizer, max_length)\n",
    "reddit_val = fun.Reddit(x_val, y_val, tokenizer, max_length)\n",
    "reddit_test = fun.Reddit(x_test, y_test, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 2\n",
    "trainloader, validationloader, testloader = fun.get_data_loaders(reddit_train, reddit_val, reddit_test, batch_size, num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bertconfig = BertConfig()\n",
    "bert_large = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "#freeze params\n",
    "for param in bert_large.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert_for_sarcasm(\n",
       "  (input_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_model = fun.bert_for_sarcasm(bert_large)\n",
    "sarcasm_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295425\n",
      "335437313\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in sarcasm_model.parameters() if p.requires_grad))\n",
    "print(sum(p.numel() for p in sarcasm_model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Elapsed [0:00:00], Iteration [1/12635]Loss: 0.6853\n",
      "Elapsed [0:04:17], Iteration [2001/12635]Loss: 0.6814\n",
      "Elapsed [0:08:35], Iteration [4001/12635]Loss: 0.7279\n",
      "Elapsed [0:12:53], Iteration [6001/12635]Loss: 0.6683\n",
      "Elapsed [0:17:10], Iteration [8001/12635]Loss: 0.6731\n",
      "Elapsed [0:21:28], Iteration [10001/12635]Loss: 0.7472\n",
      "Elapsed [0:25:46], Iteration [12001/12635]Loss: 0.6502\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp.ckpt\n",
      "Calculating validation accuracy....\n",
      "Epoch 1. Training accuracy: 0.61. Validation accuracy: 0.63.\n",
      "Epoch:  2\n",
      "Elapsed [0:30:31], Iteration [1/12635]Loss: 0.6400\n",
      "Elapsed [0:34:48], Iteration [2001/12635]Loss: 0.6239\n",
      "Elapsed [0:39:05], Iteration [4001/12635]Loss: 0.6872\n",
      "Elapsed [0:43:23], Iteration [6001/12635]Loss: 0.6475\n",
      "Elapsed [0:47:40], Iteration [8001/12635]Loss: 0.6393\n",
      "Elapsed [0:51:57], Iteration [10001/12635]Loss: 0.6405\n",
      "Elapsed [0:56:14], Iteration [12001/12635]Loss: 0.6459\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp.ckpt\n",
      "Calculating validation accuracy....\n",
      "Epoch 2. Training accuracy: 0.63. Validation accuracy: 0.64.\n",
      "Epoch:  3\n",
      "Elapsed [1:00:59], Iteration [1/12635]Loss: 0.6631\n",
      "Elapsed [1:05:17], Iteration [2001/12635]Loss: 0.6364\n",
      "Elapsed [1:09:34], Iteration [4001/12635]Loss: 0.6561\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "#Training sarcasm bert\n",
    "Epochs = 4\n",
    "\n",
    "optimizer = torch.optim.AdamW(sarcasm_model.parameters(),lr = 1e-4,eps = 1e-8)\n",
    "loss_function = nn.BCELoss()\n",
    "model_save_dir = \"/projectnb/dl523/students/nannkat/Project/training/cp.ckpt\"\n",
    "\n",
    "loss_acc = 0 \n",
    "losses = []\n",
    "\n",
    "start_time = time.time()\n",
    "num_iters = math.ceil(len(reddit_train)/ batch_size)\n",
    "\n",
    "for epoch in range(1, Epochs+1):\n",
    "    \n",
    "    print('Epoch: ',epoch)\n",
    "    train_iter = iter(trainloader)\n",
    "    sarcasm_model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for idx, (encodings, labels) in enumerate(train_iter):\n",
    "\n",
    "        labels = labels.to(device).float()\n",
    "       \n",
    "        inputs = encodings['input_ids']\n",
    "        attention_mask = encodings['attention_mask']\n",
    "       \n",
    "        inputs, attention_mask = inputs.to(device), attention_mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = sarcasm_model(inputs, attention_mask)\n",
    "        output = torch.flatten(output)\n",
    "    \n",
    "        \n",
    "        loss = loss_function(output,labels)\n",
    "        losses.append(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        output[output<0.5] = 0\n",
    "        output[output>=0.5] = 1\n",
    "        train_correct += (output == labels).float().sum().item()\n",
    "        train_total += len(labels)\n",
    "        \n",
    "        \n",
    "        loss_acc +=loss.item()\n",
    "    \n",
    "        if idx%2000 == 0:\n",
    "            et = time.time() - start_time\n",
    "            et = str(datetime.timedelta(seconds=et))[:-7]\n",
    "            log = \"Elapsed [{}], Iteration [{}/{}]\".format(et, idx+1, num_iters)\n",
    "            log += \"Loss: {:.4f}\".format(loss)\n",
    "            print(log)\n",
    "            \n",
    "    # at the end of each epoch, save model calculate validation loss + accuracy and display train accuracy vs val accuracy\n",
    "    torch.save({'epoch': epoch,\n",
    "            'model_state_dict': sarcasm_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss}, model_save_dir)\n",
    "    \n",
    "    print(\"Model checkpoint saved to \" + model_save_dir)\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    sarcasm_model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    print(\"Calculating validation accuracy....\")\n",
    "    for encodings, labels in validationloader:\n",
    "        inputs = encodings['input_ids']\n",
    "        attention_mask = encodings['attention_mask']\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            labels = labels.to(device).float()\n",
    "            inputs, attention_mask = inputs.to(device), attention_mask.to(device)\n",
    "            \n",
    "        preds = sarcasm_model(inputs, attention_mask)\n",
    "        preds = torch.flatten(preds)\n",
    "        loss = loss_function(preds,labels)\n",
    "        \n",
    "        preds[preds<0.5] = 0\n",
    "        preds[preds >=0.5] = 1\n",
    "        \n",
    "        val_correct += (preds == labels).float().sum().item()\n",
    "        val_total += len(labels)\n",
    "        \n",
    "    training_acc = round(train_correct/train_total,2)\n",
    "    validation_acc = round(val_correct/val_total,2)\n",
    "    print(\"Epoch {}. Training accuracy: {}. Validation accuracy: {}.\".format(epoch, training_acc, validation_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Losses\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training Losses\")\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "final_pred = []\n",
    "final_lab = []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for encodings, labels in testloader:\n",
    "        inputs = encodings['input_ids']\n",
    "        attention_mask = encodings['attention_mask']\n",
    "        inputs, attention_mask = inputs.to(device), attention_mask.to(device)\n",
    "        output = sarcasm_model(inputs,attention_mask).cpu()\n",
    "        preds = output.data.max(1, keepdim=True)[1].squeeze(1).numpy()\n",
    "        l = labels.cpu().numpy()\n",
    "        comp = l == preds\n",
    "        final_lab.extend(l)\n",
    "        final_pred.extend(preds)\n",
    "        for i in range(l.size):\n",
    "            if comp[i] == True:\n",
    "                correct.append(1)\n",
    "            else:\n",
    "                correct.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPrecision, Recall and Accuracy for Reddit Data:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Sarcastic       0.61      0.70      0.65     50540\n",
      "Not Sarcastic       0.65      0.55      0.60     50537\n",
      "\n",
      "     accuracy                           0.63    101077\n",
      "    macro avg       0.63      0.63      0.63    101077\n",
      " weighted avg       0.63      0.63      0.63    101077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_words = [\"Sarcastic\",\"Not Sarcastic\"]\n",
    "class_report = classification_report(final_lab,final_pred,target_names =r_words)\n",
    "print('\\033[1m'+'Precision, Recall and Accuracy for Reddit Data:\\n')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
