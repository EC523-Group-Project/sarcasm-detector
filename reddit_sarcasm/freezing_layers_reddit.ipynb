{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b9265b-c829-4c69-94a6-b44e077058fb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b7feebd-eee4-434f-b7e7-8150f2902af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "except ImportError as e:\n",
    "    print('transformers not installed')\n",
    "    print('Installing now...')\n",
    "    !pip install -q git+https://github.com/huggingface/transformers.git\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd30d18f-22d0-408d-a252-078f49c77aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import reddit_bert_functions as fun\n",
    "from bert_sarcasm_model import bert_for_sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8114864-e656-41fd-932a-ba647209e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import transformers\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers.utils.dummy_pt_objects import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForTokenClassification,AutoConfig, AutoModel,AutoTokenizer,BertModel,BertConfig,AdamW, get_constant_schedule,BertForSequenceClassification,get_linear_schedule_with_warmup\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1600c-0b4b-4089-b37d-22ae8edd6713",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d883b762-b187-49ed-806b-3b756724764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save_dir = \"/projectnb/dl523/students/nannkat/Project/training/cp_freeze.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2e13d-e69d-4f65-9efa-4283510ff49a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed625ce8-f1f4-4516-95a8-682076d2bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'train-balanced-sarcasm.csv'\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = fun.split_reddit_data(csv_path)\n",
    "\n",
    "max_length = 35  #based on word count bar plot above, 35 is reasonable\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "reddit_train = fun.Reddit(x_train, y_train, tokenizer, max_length)\n",
    "reddit_val = fun.Reddit(x_val, y_val, tokenizer, max_length)\n",
    "reddit_test = fun.Reddit(x_test, y_test, tokenizer, max_length)\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "trainloader, validationloader, testloader = fun.get_data_loaders(reddit_train, reddit_val, reddit_test, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881a13f7-e6c6-4d0a-8539-2dd687d310b2",
   "metadata": {},
   "source": [
    "## Freeze tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "999859a6-e0de-45e2-ad3e-e099a36a99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_tuning(trainloader, validationloader, layer_counts, epoch_count, batch_size, learning_rate, device):\n",
    "    print(device)\n",
    "    ##loop over layer idx\n",
    "    freeze_losses = []\n",
    "    best_loss = float('inf')\n",
    "    best_count = 0\n",
    "    for i, num_layers in enumerate(layer_counts):\n",
    "        \n",
    "        print(\"Test {}/{}\".format(i+1, len(layer_counts)))\n",
    "        print(\"Number of layers to be unfrozen: {}\".format(num_layers))\n",
    "        print()\n",
    "        \n",
    "        #create new model/freeze appropriate\n",
    "        bertconfig = BertConfig()\n",
    "        bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        fun.freeze_by_children(bert, num_layers)\n",
    "        sarcasm_model = bert_for_sarcasm(bert)\n",
    "    \n",
    "        #train over x epochs\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(device)\n",
    "        loss_function = nn.BCELoss()\n",
    "        sarcasm_model.to(device)\n",
    "        losses,val_losses = fun.train_reddit(sarcasm_model, trainloader, validationloader, epoch_count, \n",
    "                                              batch_size, device, lr = learning_rate, \n",
    "                                              model_save_dir = checkpoint_save_dir)\n",
    "        \n",
    "        curr_loss = min(val_losses)\n",
    "        \n",
    "        \n",
    "        #add loss to losses array and update best if it beats best\n",
    "        freeze_losses.append(curr_loss)\n",
    "        if curr_loss < best_loss:\n",
    "            best_loss = curr_loss\n",
    "            best_count = num_layers\n",
    "            \n",
    "        print(\"Training done!\")\n",
    "        print(\"Loss for {} layers is {}. Best loss is {} for {} layers\".format(num_layers, round(curr_loss, 4), \n",
    "                                                                               round(best_loss, 4), best_count))\n",
    "        print()\n",
    "        \n",
    "    \n",
    "    return freeze_losses, best_loss, best_count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456945ff-3dc7-45b3-8ec4-ffa63672b18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Test 1/3\n",
      "Number of layers to be unfrozen: 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input model has 12 encoding layers\n",
      "The model has 1 pooling layers\n",
      "Bert layer 10 has been unfrozen\n",
      "Bert layer 11 has been unfrozen\n",
      "Bert layer 12 has been unfrozen\n",
      "Pooling layer has been unfrozen\n",
      "cuda\n",
      "Epoch:  1\n",
      "Elapsed [0:00:00], Iteration [1/12635]Loss: 0.6962\n",
      "Elapsed [0:03:03], Iteration [2001/12635]Loss: 0.5439\n",
      "Elapsed [0:06:05], Iteration [4001/12635]Loss: 0.5215\n",
      "Elapsed [0:09:07], Iteration [6001/12635]Loss: 0.5708\n",
      "Elapsed [0:12:10], Iteration [8001/12635]Loss: 0.4953\n",
      "Elapsed [0:15:13], Iteration [10001/12635]Loss: 0.4374\n",
      "Elapsed [0:18:15], Iteration [12001/12635]Loss: 0.6449\n",
      "Validating.....\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New lowest loss, saving model...\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp_freeze.ckpt\n",
      "Epoch 1. Training accuracy: 0.73. Validation accuracy: 0.7543.\n",
      "\n",
      "Epoch:  2\n",
      "Elapsed [0:20:17], Iteration [1/12635]Loss: 0.4831\n",
      "Elapsed [0:23:19], Iteration [2001/12635]Loss: 0.5980\n",
      "Elapsed [0:26:22], Iteration [4001/12635]Loss: 0.5217\n",
      "Elapsed [0:29:24], Iteration [6001/12635]Loss: 0.4661\n",
      "Elapsed [0:32:27], Iteration [8001/12635]Loss: 0.5326\n",
      "Elapsed [0:35:29], Iteration [10001/12635]Loss: 0.5807\n",
      "Elapsed [0:38:32], Iteration [12001/12635]Loss: 0.4754\n",
      "Validating.....\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New lowest loss, saving model...\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp_freeze.ckpt\n",
      "Epoch 2. Training accuracy: 0.7629. Validation accuracy: 0.7637.\n",
      "\n",
      "Epoch:  3\n",
      "Elapsed [0:40:33], Iteration [1/12635]Loss: 0.3358\n",
      "Elapsed [0:43:36], Iteration [2001/12635]Loss: 0.4934\n",
      "Elapsed [0:46:38], Iteration [4001/12635]Loss: 0.4030\n",
      "Elapsed [0:49:40], Iteration [6001/12635]Loss: 0.5173\n",
      "Elapsed [0:52:43], Iteration [8001/12635]Loss: 0.4222\n",
      "Elapsed [0:55:45], Iteration [10001/12635]Loss: 0.4728\n",
      "Elapsed [0:58:48], Iteration [12001/12635]Loss: 0.3577\n",
      "Validating.....\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New lowest loss, saving model...\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp_freeze.ckpt\n",
      "Epoch 3. Training accuracy: 0.778. Validation accuracy: 0.7718.\n",
      "\n",
      "Epoch:  4\n",
      "Elapsed [1:00:49], Iteration [1/12635]Loss: 0.4003\n",
      "Elapsed [1:03:52], Iteration [2001/12635]Loss: 0.3123\n",
      "Elapsed [1:06:53], Iteration [4001/12635]Loss: 0.5381\n",
      "Elapsed [1:09:55], Iteration [6001/12635]Loss: 0.6096\n",
      "Elapsed [1:12:57], Iteration [8001/12635]Loss: 0.4051\n",
      "Elapsed [1:15:58], Iteration [10001/12635]Loss: 0.4379\n",
      "Elapsed [1:19:00], Iteration [12001/12635]Loss: 0.3537\n",
      "Validating.....\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New lowest loss, saving model...\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp_freeze.ckpt\n",
      "Epoch 4. Training accuracy: 0.7901. Validation accuracy: 0.7755.\n",
      "\n",
      "Epoch:  5\n",
      "Elapsed [1:21:01], Iteration [1/12635]Loss: 0.4027\n",
      "Elapsed [1:24:03], Iteration [2001/12635]Loss: 0.4521\n",
      "Elapsed [1:27:05], Iteration [4001/12635]Loss: 0.5209\n",
      "Elapsed [1:30:07], Iteration [6001/12635]Loss: 0.4496\n",
      "Elapsed [1:33:08], Iteration [8001/12635]Loss: 0.4325\n",
      "Elapsed [1:36:10], Iteration [10001/12635]Loss: 0.4715\n",
      "Elapsed [1:39:11], Iteration [12001/12635]Loss: 0.3811\n",
      "Validating.....\n",
      "No decrease in validation loss! 2 more consecutive loss increase(s) until early stop.\n",
      "Epoch 5. Training accuracy: 0.8016. Validation accuracy: 0.7754.\n",
      "\n",
      "Epoch:  6\n",
      "Elapsed [1:41:11], Iteration [1/12635]Loss: 0.4610\n",
      "Elapsed [1:44:13], Iteration [2001/12635]Loss: 0.4755\n",
      "Elapsed [1:47:15], Iteration [4001/12635]Loss: 0.3757\n",
      "Elapsed [1:50:16], Iteration [6001/12635]Loss: 0.4020\n",
      "Elapsed [1:53:18], Iteration [8001/12635]Loss: 0.3866\n",
      "Elapsed [1:56:19], Iteration [10001/12635]Loss: 0.3729\n",
      "Elapsed [1:59:21], Iteration [12001/12635]Loss: 0.3644\n",
      "Validating.....\n",
      "No decrease in validation loss! 1 more consecutive loss increase(s) until early stop.\n",
      "Epoch 6. Training accuracy: 0.8125. Validation accuracy: 0.7743.\n",
      "\n",
      "Epoch:  7\n",
      "Elapsed [2:01:21], Iteration [1/12635]Loss: 0.3434\n",
      "Elapsed [2:04:23], Iteration [2001/12635]Loss: 0.3969\n",
      "Elapsed [2:07:25], Iteration [4001/12635]Loss: 0.3968\n",
      "Elapsed [2:10:26], Iteration [6001/12635]Loss: 0.4063\n",
      "Elapsed [2:13:28], Iteration [8001/12635]Loss: 0.3251\n",
      "Elapsed [2:16:30], Iteration [10001/12635]Loss: 0.3206\n",
      "Elapsed [2:19:32], Iteration [12001/12635]Loss: 0.4446\n",
      "Validating.....\n",
      "Early stopping triggered. Ending training..\n",
      "Training done!\n",
      "Loss for 3 layers is 0.4732. Best loss is 0.4732 for 3 layers\n",
      "\n",
      "Test 2/3\n",
      "Number of layers to be unfrozen: 6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input model has 12 encoding layers\n",
      "The model has 1 pooling layers\n",
      "Bert layer 7 has been unfrozen\n",
      "Bert layer 8 has been unfrozen\n",
      "Bert layer 9 has been unfrozen\n",
      "Bert layer 10 has been unfrozen\n",
      "Bert layer 11 has been unfrozen\n",
      "Bert layer 12 has been unfrozen\n",
      "Pooling layer has been unfrozen\n",
      "cuda\n",
      "Epoch:  1\n",
      "Elapsed [0:00:00], Iteration [1/12635]Loss: 0.6856\n",
      "Elapsed [0:03:23], Iteration [2001/12635]Loss: 0.5485\n",
      "Elapsed [0:06:47], Iteration [4001/12635]Loss: 0.4537\n",
      "Elapsed [0:10:10], Iteration [6001/12635]Loss: 0.5322\n",
      "Elapsed [0:13:34], Iteration [8001/12635]Loss: 0.5506\n",
      "Elapsed [0:16:57], Iteration [10001/12635]Loss: 0.4415\n",
      "Elapsed [0:20:21], Iteration [12001/12635]Loss: 0.5106\n",
      "Validating.....\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New lowest loss, saving model...\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp_freeze.ckpt\n",
      "Epoch 1. Training accuracy: 0.7437. Validation accuracy: 0.7664.\n",
      "\n",
      "Epoch:  2\n",
      "Elapsed [0:22:30], Iteration [1/12635]Loss: 0.6265\n",
      "Elapsed [0:25:53], Iteration [2001/12635]Loss: 0.5126\n",
      "Elapsed [0:29:17], Iteration [4001/12635]Loss: 0.5494\n",
      "Elapsed [0:32:40], Iteration [6001/12635]Loss: 0.4254\n",
      "Elapsed [0:36:04], Iteration [8001/12635]Loss: 0.5552\n",
      "Elapsed [0:39:28], Iteration [10001/12635]Loss: 0.4952\n",
      "Elapsed [0:42:51], Iteration [12001/12635]Loss: 0.5219\n",
      "Validating.....\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New lowest loss, saving model...\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp_freeze.ckpt\n",
      "Epoch 2. Training accuracy: 0.7774. Validation accuracy: 0.7725.\n",
      "\n",
      "Epoch:  3\n",
      "Elapsed [0:45:00], Iteration [1/12635]Loss: 0.4482\n",
      "Elapsed [0:48:24], Iteration [2001/12635]Loss: 0.3719\n",
      "Elapsed [0:51:47], Iteration [4001/12635]Loss: 0.4538\n",
      "Elapsed [0:55:11], Iteration [6001/12635]Loss: 0.4257\n",
      "Elapsed [0:58:35], Iteration [8001/12635]Loss: 0.3775\n",
      "Elapsed [1:01:58], Iteration [10001/12635]Loss: 0.4180\n",
      "Elapsed [1:05:22], Iteration [12001/12635]Loss: 0.4565\n",
      "Validating.....\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New lowest loss, saving model...\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp_freeze.ckpt\n",
      "Epoch 3. Training accuracy: 0.7957. Validation accuracy: 0.777.\n",
      "\n",
      "Epoch:  4\n",
      "Elapsed [1:07:31], Iteration [1/12635]Loss: 0.4994\n",
      "Elapsed [1:10:54], Iteration [2001/12635]Loss: 0.2831\n",
      "Elapsed [1:14:17], Iteration [4001/12635]Loss: 0.3437\n",
      "Elapsed [1:17:41], Iteration [6001/12635]Loss: 0.3984\n",
      "Elapsed [1:21:04], Iteration [8001/12635]Loss: 0.4784\n",
      "Elapsed [1:24:28], Iteration [10001/12635]Loss: 0.3957\n",
      "Elapsed [1:27:51], Iteration [12001/12635]Loss: 0.4002\n",
      "Validating.....\n",
      "No decrease in validation loss! 2 more consecutive loss increase(s) until early stop.\n",
      "Epoch 4. Training accuracy: 0.8132. Validation accuracy: 0.7763.\n",
      "\n",
      "Epoch:  5\n",
      "Elapsed [1:29:58], Iteration [1/12635]Loss: 0.4386\n",
      "Elapsed [1:33:21], Iteration [2001/12635]Loss: 0.3972\n",
      "Elapsed [1:36:45], Iteration [4001/12635]Loss: 0.3825\n",
      "Elapsed [1:40:08], Iteration [6001/12635]Loss: 0.3676\n",
      "Elapsed [1:43:32], Iteration [8001/12635]Loss: 0.3504\n",
      "Elapsed [1:46:55], Iteration [10001/12635]Loss: 0.3390\n",
      "Elapsed [1:50:19], Iteration [12001/12635]Loss: 0.4316\n",
      "Validating.....\n",
      "No decrease in validation loss! 1 more consecutive loss increase(s) until early stop.\n",
      "Epoch 5. Training accuracy: 0.8305. Validation accuracy: 0.7742.\n",
      "\n",
      "Epoch:  6\n",
      "Elapsed [1:52:25], Iteration [1/12635]Loss: 0.4974\n",
      "Elapsed [1:55:49], Iteration [2001/12635]Loss: 0.2560\n",
      "Elapsed [1:59:12], Iteration [4001/12635]Loss: 0.4115\n",
      "Elapsed [2:02:35], Iteration [6001/12635]Loss: 0.2928\n",
      "Elapsed [2:05:59], Iteration [8001/12635]Loss: 0.1550\n",
      "Elapsed [2:09:22], Iteration [10001/12635]Loss: 0.3939\n",
      "Elapsed [2:12:46], Iteration [12001/12635]Loss: 0.2668\n",
      "Validating.....\n",
      "Early stopping triggered. Ending training..\n",
      "Training done!\n",
      "Loss for 6 layers is 0.4648. Best loss is 0.4648 for 6 layers\n",
      "\n",
      "Test 3/3\n",
      "Number of layers to be unfrozen: 12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input model has 12 encoding layers\n",
      "The model has 1 pooling layers\n",
      "Bert layer 1 has been unfrozen\n",
      "Bert layer 2 has been unfrozen\n",
      "Bert layer 3 has been unfrozen\n",
      "Bert layer 4 has been unfrozen\n",
      "Bert layer 5 has been unfrozen\n",
      "Bert layer 6 has been unfrozen\n",
      "Bert layer 7 has been unfrozen\n",
      "Bert layer 8 has been unfrozen\n",
      "Bert layer 9 has been unfrozen\n",
      "Bert layer 10 has been unfrozen\n",
      "Bert layer 11 has been unfrozen\n",
      "Bert layer 12 has been unfrozen\n",
      "Pooling layer has been unfrozen\n",
      "cuda\n",
      "Epoch:  1\n",
      "Elapsed [0:00:00], Iteration [1/12635]Loss: 0.6825\n",
      "Elapsed [0:04:08], Iteration [2001/12635]Loss: 0.4932\n",
      "Elapsed [0:08:16], Iteration [4001/12635]Loss: 0.4355\n",
      "Elapsed [0:12:24], Iteration [6001/12635]Loss: 0.4586\n",
      "Elapsed [0:16:32], Iteration [8001/12635]Loss: 0.4297\n",
      "Elapsed [0:20:41], Iteration [10001/12635]Loss: 0.5614\n",
      "Elapsed [0:24:49], Iteration [12001/12635]Loss: 0.3751\n",
      "Validating.....\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New lowest loss, saving model...\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp_freeze.ckpt\n",
      "Epoch 1. Training accuracy: 0.75. Validation accuracy: 0.7735.\n",
      "\n",
      "Epoch:  2\n",
      "Elapsed [0:27:12], Iteration [1/12635]Loss: 0.5485\n",
      "Elapsed [0:31:20], Iteration [2001/12635]Loss: 0.4622\n",
      "Elapsed [0:35:29], Iteration [4001/12635]Loss: 0.5364\n",
      "Elapsed [0:39:37], Iteration [6001/12635]Loss: 0.2726\n",
      "Elapsed [0:43:45], Iteration [8001/12635]Loss: 0.4832\n",
      "Elapsed [0:47:53], Iteration [10001/12635]Loss: 0.4215\n",
      "Elapsed [0:52:01], Iteration [12001/12635]Loss: 0.4560\n",
      "Validating.....\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New lowest loss, saving model...\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp_freeze.ckpt\n",
      "Epoch 2. Training accuracy: 0.7891. Validation accuracy: 0.7785.\n",
      "\n",
      "Epoch:  3\n",
      "Elapsed [0:54:25], Iteration [1/12635]Loss: 0.3913\n",
      "Elapsed [0:58:33], Iteration [2001/12635]Loss: 0.4521\n",
      "Elapsed [1:02:41], Iteration [4001/12635]Loss: 0.4199\n",
      "Elapsed [1:06:49], Iteration [6001/12635]Loss: 0.4065\n",
      "Elapsed [1:10:57], Iteration [8001/12635]Loss: 0.3563\n",
      "Elapsed [1:15:05], Iteration [10001/12635]Loss: 0.3777\n",
      "Elapsed [1:19:13], Iteration [12001/12635]Loss: 0.3998\n",
      "Validating.....\n",
      "No decrease in validation loss! 2 more consecutive loss increase(s) until early stop.\n",
      "Epoch 3. Training accuracy: 0.8161. Validation accuracy: 0.7769.\n",
      "\n",
      "Epoch:  4\n",
      "Elapsed [1:21:34], Iteration [1/12635]Loss: 0.1928\n",
      "Elapsed [1:25:42], Iteration [2001/12635]Loss: 0.3958\n",
      "Elapsed [1:29:49], Iteration [4001/12635]Loss: 0.3277\n",
      "Elapsed [1:33:57], Iteration [6001/12635]Loss: 0.3355\n",
      "Elapsed [1:38:06], Iteration [8001/12635]Loss: 0.2250\n",
      "Elapsed [1:42:15], Iteration [10001/12635]Loss: 0.3378\n",
      "Elapsed [1:46:25], Iteration [12001/12635]Loss: 0.3281\n",
      "Validating.....\n",
      "No decrease in validation loss! 1 more consecutive loss increase(s) until early stop.\n",
      "Epoch 4. Training accuracy: 0.8437. Validation accuracy: 0.7747.\n",
      "\n",
      "Epoch:  5\n",
      "Elapsed [1:48:48], Iteration [1/12635]Loss: 0.4012\n",
      "Elapsed [1:52:58], Iteration [2001/12635]Loss: 0.3007\n",
      "Elapsed [1:57:07], Iteration [4001/12635]Loss: 0.2726\n",
      "Elapsed [2:01:17], Iteration [6001/12635]Loss: 0.3733\n",
      "Elapsed [2:05:27], Iteration [8001/12635]Loss: 0.2809\n",
      "Elapsed [2:09:37], Iteration [10001/12635]Loss: 0.3252\n",
      "Elapsed [2:13:47], Iteration [12001/12635]Loss: 0.3742\n",
      "Validating.....\n",
      "Early stopping triggered. Ending training..\n",
      "Training done!\n",
      "Loss for 12 layers is 0.4672. Best loss is 0.4648 for 6 layers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 1e-5\n",
    "layer_counts = [3 , 6 , 12]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "freeze_losses, best_loss, best_count = freeze_tuning(trainloader, validationloader, layer_counts,\n",
    "                                                     epoch_count = epochs, batch_size = batch_size, learning_rate = lr,\n",
    "                                                    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f02b261a-bb87-45b0-bd88-bb8587ca098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers unfroze: 3 Loss: 0.47319089902352685\n",
      "Layers unfroze: 6 Loss: 0.464794858384736\n",
      "Layers unfroze: 12 Loss: 0.4671874969065944\n"
     ]
    }
   ],
   "source": [
    "for i, num in enumerate(layer_counts):\n",
    "    print(\"Layers unfroze: {} Loss: {}\".format(num, freeze_losses[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f257c55-7b29-4e3f-9c5d-9829a1420e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
