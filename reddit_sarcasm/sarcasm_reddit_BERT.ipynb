{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test running pretrained BERT on reddit data\n",
    "- Maybe start adding multi level attention blocks at the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "except ImportError as e:\n",
    "    print('transformers not installed')\n",
    "    print('Installing now...')\n",
    "    !pip install -q git+https://github.com/huggingface/transformers.git\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reddit_bert_functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import transformers\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers.utils.dummy_pt_objects import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForTokenClassification,AutoConfig, AutoModel,AutoTokenizer,BertModel,BertConfig,AdamW, get_constant_schedule,BertForSequenceClassification,get_linear_schedule_with_warmup\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import reddit dataset, split and create PyTorch data class objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'train-balanced-sarcasm.csv'\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = fun.split_reddit_data(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count per each sample\n",
    "count = x_train.str.split().str.len()\n",
    "plt.hist(count, bins=30, range=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if even split between labels\n",
    "import seaborn as sns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 7))\n",
    "fig.suptitle('Distribution of Classes Reddit\\n0:Non-Sarcastic vs. 1:Sarcastic accross data splits')\n",
    "sns.countplot(ax=axes[0], x=y_train)\n",
    "axes[0].set_title('Training Set')\n",
    "sns.countplot(ax=axes[1], x=y_val)\n",
    "axes[1].set_title('Validation Set')\n",
    "sns.countplot(ax=axes[2], x=y_test)\n",
    "axes[2].set_title('Test Set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 35  #based on word count bar plot above, 35 is reasonable\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "reddit_train = fun.Reddit(x_train, y_train, tokenizer, max_length)\n",
    "reddit_val = fun.Reddit(x_val, y_val, tokenizer, max_length)\n",
    "reddit_test = fun.Reddit(x_test, y_test, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 2\n",
    "trainloader, validationloader, testloader = fun.get_data_loaders(reddit_train, reddit_val, reddit_test, batch_size, num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bertconfig = BertConfig()\n",
    "bert_large = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "#freeze params\n",
    "for param in bert_large.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "recover = True\n",
    "model_save_dir = \"/projectnb/dl523/students/nannkat/Project/training/cp.ckpt\"\n",
    "\n",
    "sarcasm_model = fun.bert_for_sarcasm(bert_large)\n",
    "\n",
    "if recover:\n",
    "    #load weights from checkpoint if applicable\n",
    "    checkpoint = torch.load(model_save_dir)\n",
    "    sarcasm_model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert_for_sarcasm(\n",
       "  (input_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295425\n",
      "335437313\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in sarcasm_model.parameters() if p.requires_grad))\n",
    "print(sum(p.numel() for p in sarcasm_model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n",
      "Elapsed [0:00:06], Iteration [1/12635]Loss: 0.6296\n",
      "Elapsed [0:04:45], Iteration [2001/12635]Loss: 0.5943\n",
      "Elapsed [0:09:24], Iteration [4001/12635]Loss: 0.6000\n",
      "Elapsed [0:14:02], Iteration [6001/12635]Loss: 0.5475\n",
      "Elapsed [0:18:41], Iteration [8001/12635]Loss: 0.6566\n",
      "Elapsed [0:23:20], Iteration [10001/12635]Loss: 0.6394\n",
      "Elapsed [0:27:59], Iteration [12001/12635]Loss: 0.5607\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp.ckpt\n",
      "Calculating validation accuracy....\n",
      "Epoch 4. Training accuracy: 0.64. Validation accuracy: 0.66.\n",
      "Epoch:  5\n",
      "Elapsed [0:33:09], Iteration [1/12635]Loss: 0.6431\n",
      "Elapsed [0:37:48], Iteration [2001/12635]Loss: 0.6125\n",
      "Elapsed [0:42:27], Iteration [4001/12635]Loss: 0.6671\n",
      "Elapsed [0:47:06], Iteration [6001/12635]Loss: 0.6009\n",
      "Elapsed [0:51:45], Iteration [8001/12635]Loss: 0.5918\n",
      "Elapsed [0:56:24], Iteration [10001/12635]Loss: 0.6055\n",
      "Elapsed [1:01:04], Iteration [12001/12635]Loss: 0.6115\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp.ckpt\n",
      "Calculating validation accuracy....\n",
      "Epoch 5. Training accuracy: 0.64. Validation accuracy: 0.66.\n",
      "Epoch:  6\n",
      "Elapsed [1:06:14], Iteration [1/12635]Loss: 0.6565\n",
      "Elapsed [1:10:53], Iteration [2001/12635]Loss: 0.6014\n",
      "Elapsed [1:15:33], Iteration [4001/12635]Loss: 0.6726\n",
      "Elapsed [1:20:12], Iteration [6001/12635]Loss: 0.5716\n",
      "Elapsed [1:24:51], Iteration [8001/12635]Loss: 0.6874\n",
      "Elapsed [1:29:30], Iteration [10001/12635]Loss: 0.6215\n",
      "Elapsed [1:34:09], Iteration [12001/12635]Loss: 0.6236\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp.ckpt\n",
      "Calculating validation accuracy....\n",
      "Epoch 6. Training accuracy: 0.64. Validation accuracy: 0.64.\n",
      "Epoch:  7\n",
      "Elapsed [1:39:19], Iteration [1/12635]Loss: 0.7162\n",
      "Elapsed [1:43:58], Iteration [2001/12635]Loss: 0.6041\n",
      "Elapsed [1:48:37], Iteration [4001/12635]Loss: 0.6692\n",
      "Elapsed [1:53:15], Iteration [6001/12635]Loss: 0.6773\n",
      "Elapsed [1:57:55], Iteration [8001/12635]Loss: 0.5606\n",
      "Elapsed [2:02:34], Iteration [10001/12635]Loss: 0.6805\n",
      "Elapsed [2:07:13], Iteration [12001/12635]Loss: 0.6635\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp.ckpt\n",
      "Calculating validation accuracy....\n",
      "Epoch 7. Training accuracy: 0.64. Validation accuracy: 0.66.\n",
      "Epoch:  8\n",
      "Elapsed [2:12:23], Iteration [1/12635]Loss: 0.6360\n",
      "Elapsed [2:17:01], Iteration [2001/12635]Loss: 0.6595\n",
      "Elapsed [2:21:40], Iteration [4001/12635]Loss: 0.6139\n",
      "Elapsed [2:26:19], Iteration [6001/12635]Loss: 0.7071\n",
      "Elapsed [2:30:58], Iteration [8001/12635]Loss: 0.6188\n",
      "Elapsed [2:35:37], Iteration [10001/12635]Loss: 0.6268\n",
      "Elapsed [2:40:15], Iteration [12001/12635]Loss: 0.6576\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp.ckpt\n",
      "Calculating validation accuracy....\n",
      "Epoch 8. Training accuracy: 0.64. Validation accuracy: 0.66.\n",
      "Epoch:  9\n",
      "Elapsed [2:45:25], Iteration [1/12635]Loss: 0.5441\n",
      "Elapsed [2:50:04], Iteration [2001/12635]Loss: 0.6800\n",
      "Elapsed [2:54:43], Iteration [4001/12635]Loss: 0.6932\n",
      "Elapsed [2:59:22], Iteration [6001/12635]Loss: 0.5895\n",
      "Elapsed [3:04:01], Iteration [8001/12635]Loss: 0.6036\n",
      "Elapsed [3:08:40], Iteration [10001/12635]Loss: 0.5866\n",
      "Elapsed [3:13:19], Iteration [12001/12635]Loss: 0.5306\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp.ckpt\n",
      "Calculating validation accuracy....\n",
      "Epoch 9. Training accuracy: 0.65. Validation accuracy: 0.66.\n",
      "Epoch:  10\n",
      "Elapsed [3:18:29], Iteration [1/12635]Loss: 0.6496\n",
      "Elapsed [3:23:08], Iteration [2001/12635]Loss: 0.6665\n",
      "Elapsed [3:27:46], Iteration [4001/12635]Loss: 0.5670\n",
      "Elapsed [3:32:25], Iteration [6001/12635]Loss: 0.6550\n",
      "Elapsed [3:37:04], Iteration [8001/12635]Loss: 0.6308\n",
      "Elapsed [3:41:43], Iteration [10001/12635]Loss: 0.6174\n",
      "Elapsed [3:46:21], Iteration [12001/12635]Loss: 0.5908\n",
      "Model checkpoint saved to /projectnb/dl523/students/nannkat/Project/training/cp.ckpt\n",
      "Calculating validation accuracy....\n",
      "Epoch 10. Training accuracy: 0.65. Validation accuracy: 0.66.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "#Training sarcasm bert\n",
    "Epochs = 10\n",
    "\n",
    "if recover:\n",
    "    epoch_start = checkpoint['epoch'] + 1\n",
    "else:\n",
    "    epoch_start = 1\n",
    "\n",
    "optimizer = torch.optim.AdamW(sarcasm_model.parameters(),lr = 1e-4,eps = 1e-8)\n",
    "loss_function = nn.BCELoss()\n",
    "model_save_dir = \"/projectnb/dl523/students/nannkat/Project/training/cp.ckpt\"\n",
    "\n",
    "loss_acc = 0 \n",
    "losses = []\n",
    "\n",
    "start_time = time.time()\n",
    "num_iters = math.ceil(len(reddit_train)/ batch_size)\n",
    "\n",
    "for epoch in range(epoch_start, Epochs+1):\n",
    "    \n",
    "    print('Epoch: ',epoch)\n",
    "    train_iter = iter(trainloader)\n",
    "    sarcasm_model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for idx, (encodings, labels) in enumerate(train_iter):\n",
    "\n",
    "        labels = labels.to(device).float()\n",
    "       \n",
    "        inputs = encodings['input_ids']\n",
    "        attention_mask = encodings['attention_mask']\n",
    "       \n",
    "        inputs, attention_mask = inputs.to(device), attention_mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = sarcasm_model(inputs, attention_mask)\n",
    "        output = torch.flatten(output)\n",
    "    \n",
    "        \n",
    "        loss = loss_function(output,labels)\n",
    "        losses.append(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        output[output<0.5] = 0\n",
    "        output[output>=0.5] = 1\n",
    "        train_correct += (output == labels).float().sum().item()\n",
    "        train_total += len(labels)\n",
    "        \n",
    "        \n",
    "        loss_acc +=loss.item()\n",
    "    \n",
    "        if idx%2000 == 0:\n",
    "            et = time.time() - start_time\n",
    "            et = str(datetime.timedelta(seconds=et))[:-7]\n",
    "            log = \"Elapsed [{}], Iteration [{}/{}]\".format(et, idx+1, num_iters)\n",
    "            log += \"Loss: {:.4f}\".format(loss)\n",
    "            print(log)\n",
    "            \n",
    "    # at the end of each epoch, save model calculate validation loss + accuracy and display train accuracy vs val accuracy\n",
    "    torch.save({'epoch': epoch,\n",
    "            'model_state_dict': sarcasm_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss}, model_save_dir)\n",
    "    \n",
    "    print(\"Model checkpoint saved to \" + model_save_dir)\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    sarcasm_model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    print(\"Calculating validation accuracy....\")\n",
    "    for encodings, labels in validationloader:\n",
    "        inputs = encodings['input_ids']\n",
    "        attention_mask = encodings['attention_mask']\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            labels = labels.to(device).float()\n",
    "            inputs, attention_mask = inputs.to(device), attention_mask.to(device)\n",
    "            \n",
    "        preds = sarcasm_model(inputs, attention_mask)\n",
    "        preds = torch.flatten(preds)\n",
    "        loss = loss_function(preds,labels)\n",
    "        \n",
    "        preds[preds<0.5] = 0\n",
    "        preds[preds >=0.5] = 1\n",
    "        \n",
    "        val_correct += (preds == labels).float().sum().item()\n",
    "        val_total += len(labels)\n",
    "        \n",
    "    training_acc = round(train_correct/train_total,2)\n",
    "    validation_acc = round(val_correct/val_total,2)\n",
    "    print(\"Epoch {}. Training accuracy: {}. Validation accuracy: {}.\".format(epoch, training_acc, validation_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFNCAYAAABFbcjcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABV9UlEQVR4nO3dd5gT5doG8PvZhaX3Lm1BmhQFBQQpoqggeMByjmLXo6LfOVjwqAe7YsNesWDvYD8oCIKAoNSld1j60nuHZXef749MltlsJpkkM8lk9/5dFxfJZMq7SWbyzFueV1QVREREROQNKYkuABERERGdxOCMiIiIyEMYnBERERF5CIMzIiIiIg9hcEZERETkIQzOiIiIiDyEwRkRJSUR+VVEbnR6XSKiRBPmOSOieBGRQ6anZQEcB5BrPL9dVb+Mf6miJyI9AHyhqvUSXBQiKkJKJLoARFR8qGp5/2MRWQ/gVlWdGLieiJRQ1Zx4lo2IyCvYrElECSciPUQkS0T+KyLbAHwsIlVE5BcR2Skie43H9UzbTBGRW43HN4nInyLykrHuOhG5OMp1G4nIVBE5KCITRWS4iHwRxd90mnHcfSKyVET6mV7rIyLLjGNsFpH7jOXVjb9zn4jsEZFpIpJivHaKiHxvvB/rROQu0/46ikiGiBwQke0i8kqk5SUi72BwRkReURtAVQANAQyE7/r0sfG8AYCjAN4Ksf3ZAFYCqA7gBQAfiohEse5XAGYDqAbgCQDXR/qHiEhJAD8D+A1ATQB3AvhSRJobq3wIXzNuBQCtAUwylv8HQBaAGgBqAXgIgBoB2s8AFgKoC6AngHtEpJex3esAXlfVigBOBfBNpGUmIu9gcEZEXpEH4HFVPa6qR1V1t6p+r6pHVPUggGcAnBti+w2q+r6q5gL4FEAd+AIc2+uKSAMAHQA8pqrZqvongNFR/C2dAJQHMMzYzyQAvwC42nj9BICWIlJRVfeq6jzT8joAGqrqCVWdpr6OwR0A1FDVocb+1gJ4H8AA03ZNRKS6qh5S1ZlRlJmIPILBGRF5xU5VPeZ/IiJlReQ9EdkgIgcATAVQWURSLbbf5n+gqkeMh+UjXPcUAHtMywBgU4R/B4z9bFLVPNOyDfDVegHAFQD6ANggIn+ISGdj+YsAMgH8JiJrRWSIsbwhgFOM5s59IrIPvlo1f/B5C4BmAFaIyBwRuSSKMhORR3BAABF5ReDQ8f8AaA7gbFXdJiJtAcwHYNVU6YStAKqKSFlTgFY/iv1sAVBfRFJMAVoDAKsAQFXnAOhvNH8Ogq8Zsr5RQ/gfAP8RkdYAJonIHPgCxHWq2jTYwVR1NYCrjebPywF8JyLVVPVwFGUnogRjzRkReVUF+PqZ7RORqgAed/uAqroBQAaAJ0QkzajR+lu47USktPkffH3WjgB4QERKGik3/gZgpLHfa0WkkqqeAHAAviZdiMglItLE6P+2H740I3nG/g4aAybKiEiqiLQWkQ7GdteJSA0jENxnFMtca0dESYTBGRF51WsAygDYBWAmgHFxOu61ADoD2A3gaQCj4MvHZqUufEGk+V99+IKxi+Er/9sAblDVFcY21wNYbzTX3mEcEwCaApgI4BCAGQDeVtXJRt+4SwC0BbDO2OcHACoZ2/UGsNTII/c6gAGqejT6t4CIEolJaImIQhCRUQBWqKrrNXdERABrzoiIChCRDiJyqoikiEhvAP0B/JTgYhFRMcIBAUREBdUG8AN8ec6yAPyfqs5PbJGIqDhhsyYRERGRh7BZk4iIiMhDGJwREREReUiR6XNWvXp1TU9PT3QxiIiIiMKaO3fuLlWtEey1IhOcpaenIyMjI9HFICIiIgpLRDZYvcZmTSIiIiIPYXBGRERE5CEMzoiIiIg8hMEZERERkYcwOCMiIiLyEAZnRERERB7C4IyIiIjIQxicEREREXkIgzMiIiIiD3E1OBOR3iKyUkQyRWRIkNcbiMhkEZkvIotEpI+xPF1EjorIAuPfu26Wk4gSa+/hbCzK2pfoYhAReYJr0zeJSCqA4QAuBJAFYI6IjFbVZabVHgHwjaq+IyItAYwFkG68tkZV27pVPiLyjn+8NwOZOw5h/bC+iS4KEVHCuVlz1hFApqquVdVsACMB9A9YRwFUNB5XArDFxfIQkUdl7jiU6CIQEXmGm8FZXQCbTM+zjGVmTwC4TkSy4Ks1u9P0WiOjufMPEenmYjmJiIiIPCPRAwKuBvCJqtYD0AfA5yKSAmArgAaq2g7AvQC+EpGKgRuLyEARyRCRjJ07d8a14ERERERucDM42wygvul5PWOZ2S0AvgEAVZ0BoDSA6qp6XFV3G8vnAlgDoFngAVR1hKq2V9X2NWrUcOFPICIiIoovN4OzOQCaikgjEUkDMADA6IB1NgLoCQAichp8wdlOEalhDCiAiDQG0BTAWhfLSkREROQJro3WVNUcERkEYDyAVAAfqepSERkKIENVRwP4D4D3RWQwfIMDblJVFZHuAIaKyAkAeQDuUNU9bpWViIiIyCtcC84AQFXHwtfR37zsMdPjZQC6BNnuewDfu1k2IiIiIi9K9IAAIiIiIjJhcEZERETkIQzOiIiIiDyEwVkRdP2Hs3Dn1/MTXQwiIiKKAoOzImja6l34eSFnwiIiIkpGDM6IiMiT9h3JxjtT1kBVE10UorhicEZERJ405PvFeH7cCsxcyzSXVLwwOCMiIk86dDwHAJCTl5fgkhDFF4MzIiIiIg9hcEZERETkIQzOiIhsmr5mF3YfOp7oYhBREcfgjIjIpmven4Wr35+Z6GIQURHH4IyIKAKrth9ydf/HTuTi2IlcV49BRN7G4IyIyEPaDv0Npz02LtHFIKIEKpHoAhAR0UnHTjBtBFFxx5ozIiIiIg9hcEZERETkIQzOiIiIiDyEwRlRgm3acwSrtx9MdDGIiMgjOCCAKMG6vTAZALB+WN8El4SIiLyANWdESWb9rsNIHzIGYxZtTXRRiIjIBQzOiJLM0i0HAABjFm9JcEkolOd+XY5zX5yc6GIUCaqJLgFRfLFZk4jIBe/9sTbRRUh6IokuAVFiuFpzJiK9RWSliGSKyJAgrzcQkckiMl9EFolIH9NrDxrbrRSRXm6Wk4iIyMtUFUs27090MShOXAvORCQVwHAAFwNoCeBqEWkZsNojAL5R1XYABgB429i2pfG8FYDeAN429kdEBjb1EBUfn8/cgEve/BN/rt6V6KJQHLhZc9YRQKaqrlXVbAAjAfQPWEcBVDQeVwLg70TTH8BIVT2uqusAZBr7Iyr22NRDVPws3+rra7pxz5EEl4Tiwc3grC6ATabnWcYysycAXCciWQDGArgzgm2Jkl52DudRJCKighI9WvNqAJ+oaj0AfQB8LiK2yyQiA0UkQ0Qydu7c6Vohidzy1uTMRBeBKGEe+nEx0oeMSXQxiDzHzeBsM4D6puf1jGVmtwD4BgBUdQaA0gCq29wWqjpCVduravsaNWo4WHSi+Nh7ONu1fY+YugbpQ8bgeE6ua8coCuas34NDx3MSXYxi4fbPMzB5xY7851/N2pjA0lA8TFu9E2t2Hkp0MZKOm8HZHABNRaSRiKTB18F/dMA6GwH0BAAROQ2+4Gynsd4AESklIo0ANAUw28WyEiWdcAMC3pmyBgBw+DiDMyt7D2fjH+/OwF1fz090UYqF8Uu34+ZP5then4Nekt/1H85Gz5f/SHQxko5rec5UNUdEBgEYDyAVwEequlREhgLIUNXRAP4D4H0RGQzf4ICbVFUBLBWRbwAsA5AD4N+qyl8YIgAcD+CcY0at4jIjsS95EwfBxObAsRPIy1NULpuW6KKQTa4moVXVsfB19Dcve8z0eBmALhbbPgPgGTfLR0RE0dt7OBvZuXmoVbF0ootS5MVSi3j6E78B4Py9ySTRAwKIiChJtXtqAs5+9vdEFyOh3v1jDeZt3Bu3463ecRCLsvbF7XjxkLF+Dy5/+y/HRq+rKj6YthYHjp1wZH+JwOCMioTcPMWEZduhxaiTiqL4/K1E45ZsxY4DxyLeLic3Dzm57qWsGfbrClz+9nTX9h/o47/Wo99bf7my7zU7D2HBpn2Wr2/ZdxTfzc1y/LhDfliMeRv3YcPuw47sb/qa3Xh6zHI8+tMSR/aXCAzOqEh49481uO2zDPy2bHuii+I69r+h4iY7Jw93fDEPA96fGfG2LR8bj24vcAJ6O3q+/AcuHW4d+F3z/kzc9+1CHHZxdHNunmLj7tgS7fpHqB84ypozSjKqiiPZRSd9QNZe38n8+P+WIn3IGBw7wfEjia5XO5Kdgx0HI6/pSATWQnpbbp7v89m892jE22bn5mHr/uT4HobihUaBnQePA3D32vLi+JXo/uJkbCrmMyEwOCumvpi1ES0fG1/kToBtRrMH81adlKiKtsuGT0fHZ7zdH0ni+O5MX7OLNw0RYi1x4h3Nzo1r360Za3xzh+6OMgfkoqx9WLgp+SeIZ3BWTI1fsg0AsN6hNn6KPy/cSYeycvvBRBfBM9btOoxr3p+Fh35c7Ng+mV2fIhVNH6zzX56SP9ozGfR76y+8/vvqRBcjZgzOyJPu+3Yhfl64JdHF8ChWJySbg0bNw+rtzmVKT/bs+v6JvCl+Pp+5IeJtikKTcDJicEYJMz1zF64eMTO/P4nZd3OzcGcEWdu9XotE9tgdbXv9h7Pw4A+LYjrWlJU7sHlf0WrWTyZXvjcj0UVIKuwXWbwwOHPZvI17kT5kDLZHMQS8qLtr5HzMWLsbe1ycX7I46vHiZDwzZlmii+Gqaat34evZm2Lax00fz8EV7/gChHgH9ws37cOQ7xd5MvXLln1HMXxyputlc2P3Tvbpy87JQ7cXJmFiMRgB7iULs5K/v5gTGJy57JO/1gMAZq7dndiCJIlNe45gmwPV6G40/OXlKTJ3ONuPyo0Oz+t3H8H709Y5v2OK2a5DxzF9zS5c9+EsjJyzCQeOeW/gyh1fzMWL41di7S7v9UcNFc9lrN+DFo+Owx+rdjpyrO0HjmHTnqN4fPRSR/ZXlLgVuGdFMRq3qGJwRp7S7YXJ6PScN0f4vTkpExe8MhUrtiVHX5lg18/JK3dg3xHWVCbK1v3HcM37sxJdjJD8Oawi/QF2OtHrrZ/OwbTVvpF7YuMuZs56X5b+6cZoP3LWtxmbcDjb3dHGxx2aIaAoYHAWhe/mZmHKyh2O7nPr/qMYMXWNZ5o5xi7eymH/8P3gPPjDImTtPZI/RUuydZD1/67tP3ICN388B7d9lpHYAtm093B2kZumpqj6JmMTmjz8a36+wWDmrN8T0T4nLnf2Gusl2Tl5+YNEksX938XWxzNSxX3YE4OzKNz37ULc9PEcR/d522cZeHbsCmyMU96xYJ1LZ6/bg96vTcX0zF3415fz8OTP7vZb2nUothqcz2duwLcZvn5HbsW0s9btwdezN+EBmxemHQeOofNzv2PNTnuj8szldjsYzjZqNtbFubnqzd9X495RC2yta34/rnh3umvT1MRboXxqAd/XD/9cF9f5GZ3mH1nd9XnrTPwP/eBcGpForN91GO9PXZvQMvhd+8FMtElQeoq8IAOwnPDOlDW2z3MKj8GZRxwy+p64dN5YMv9oPDF6KVZsO4j5xtxqW/Ylvv0/VE3ioz8tsbybs9MMYu/4/v3ZW//XJduwdf8xfDp9fcTHOv1J7+YSem7sckyIsmP0yxNW4Yf5myPebu3O+AaRs9buxuBRC4J+5yYs246V25zP2+b/Xj31y7K4zs8YT7sPHcd/v1tUqMnKzVaCicu2Y8j3Ba8NV42YgWfGLo9bjdWUlTssBzv5m2AT4YXxK13Z7/PjVkR1nlNwDM6KsKVb9udfAFdsO4DJMTTF7j9ywtXJg61EGxAk2vETeTgR4fuVHaK/xZu/r8aMNQUHlTj103YiNy9/Ljor701d62hz6OrtB7HZA8G/nwK4/sPZ+HH+5vwaRrPbPstAr9emxr9gDlBVvPzbSqxPUAf/F8atxKiMTXFrFQCAWz/LwMg5m7Dr0PH8ZdsPHA+xhbVo7vOOZufipo/n4MaPZkd1zGCcimVHL4hPALUoa19UE9WHsn7XYaQPGYPJK2Jr8p63ca+r84M6gcGZR6y3OdHrjgPHsP+IvTu/vm/8iU+MGpzer03DzUGaYlfZyOKuqjhj6G+2m/acdNCDo9nGLd6G2etC958ZlbEJfV6f5tgxX56wClcbkz7HWim461B2gdxyPV6cguaPjIttpxG68NWp6DJskq11f5yf5XJpYvPVrI3oHSJwy87Jw8fTEzd6dsv+Y3hzUiZu+ti5QCESiczP1f7piYWWHbXZqd0/tV00IwhzjUhqrc3uDXZ4ozeyff3e+gs9X/kjpn3cPXJ+gXyX/qb/0TEkKN93JBuXvz0dd0WQRzMRGJwlmY7P/o4Ozxa+4FixysLtb84c+kv4fmX+O7Yfbdxx/bl6Fz78s+ikcTD/sPgfjcrYVCiB5oncPKQPGYMP/jzZp2X1jtAX5rw8jSpjt137j1oH8a9MONm04aUarGAGj1oY1+NFWkPx0I+LsSJEk+f709bih3kFzx27h1i1/WDM3Qu2GtufyI3Pz7uqhqwFTrR/fzXP1nr+7h2xcHt0o1t6vTo15OAOu9+kWG+u/7dgi6MzxeTlKY4afXuXbPF2PjUGZzH4ZVFiphfKzslzJR2CE5fu6z6chadsBHxOi+buPDsnz3ZTbbgJsv0n/KY99n9Ixyzeantdv7cmrXYkae/cDfHv83IiN8/xZo5gjmTnoNerU7Ew0h9Xl4aHhZo0OtwhL3p1Ks4x1TCqKiYs2x50Vo1g1u86jL+/G99M/COmrkWzR37FXjeSSztwkUrEdz/ZrNx+EJ/NcO/GMVLpQ8ZgaZTB1IncPLz7xxrsOHAMjR8aiw+NHJDbDxy3fR4lAoOzGAz6aj7Sh4zBRhtNks+OXW5rnws37cO01eGTKLYdOsHWF8uJfgp2drHvSDYe+1/BSXXf/H015m4IP3z+3m8W4CeHO5La+Z1t9siv6D88caMBj2RHflf50m+r8KAx6s3uZ/vJ9PWeSNHy6E9L0PHZ30P29XCilAs27cPK7Qfx3K/2zrlkMnbxNtz2WQY+mGZv1GGoWtG5G/Ziw25n+qH585EByK8l3H4weVLOLNm8v1BzpxfOGTc4NVjKSf732ly0wGL+HmVqlS9nbsCwX1fktxJ9O/dkN4k3PDxBOoMzB0zLDB9M2e2Mes+oBbj+Q3t9Q/JsXDzMHWLNgtU0ZVl02J1kdL4UAOOXbkNmkOa6F8avLHSn9fKEVbjinRnYfeg4HvlpMXYdOh40XcS01btwj8UQbHMpv5y1wfFpiZZuCZ1Qtihcn1+buDroZ9b9hckx9d0wW7ntYNgOtv7BHUeZPy9fpLU4O4yAx4lce1e8Mx3nvjjF8nW3v/teObX2HzmBS978E/eMsu6DtP3AMcxP4lQn4YyasxHDJ2fG/biHjucU+I2KJmzcvO9oyL59/qblI0GamKOtjYsHBmdJzndhmWaZu2ryyvCB48y1u7Fx9xEctPhxNY/Su/3zubjA1MkzL09x76gFmBfwI2OeS/SZMcvxxcyNaP/0RPQPkbcq3J3qwz8uSdi0RB682YxITkAt68JN+7FxzxFHOsXm5Sl6vTY1Lsltn/plGa77wPkM+6rxTXrp/64H5kt0qibL79oo3qtQNSsXvz4Nfd8IPdAl8KYxXJeAYA7FcSSd/2ZhwaZ9UFXM3bCn0LWo58t/4DKbqU5WbjuYf0ObLP77/WK86FKKDTNVxc8Lt+T3STz/pSlBB20EY3Uj02XYJJz/svXAA39aI393kFB9cb2EwZnLzKf417M32h4pBPhG+vz3u0Uh+0VNWL4dSzYfwJuTrKtnwyU3HTBiJiYsD5+yIthFe9/RE/hh/uZCHaLNI2xyTRe6lSFGhyZy6o5Dx3OCBofmJaGCRyfmA3XTtoC+Xk7VXu04eCw/qJ9lGsHqVtqVD/9chz8z3Ziexxv1OKFqsrxg+dYDYWubww2EsePx/yVmPssf52/GFe/MKFSjbA4Wj53IxTtT1lh+x3u9NtWVkYB2ajLHLdlqu6/f/qMn4p5eZdKKHbjz6/l4beIqAMCOg9YtSt/NLThKO5o5U9V0DK9fowMxOHPJ0i37sW3/MWSb8kc9+MNinPbYODR5aGz+so//Whe01mvdrsO4Z9QCjMrYFPZiGM7rNtrVo+m8u27XYcuAxRyExtI8cvDYCVv5wiI5xow1uwtclNbuPITWj4/HyDm+2QZ2HDiWP4zezNyvJtBFrzqXA+tEbh5Gzt6Yn8nb+rOx/0cHS6MSyv6jJ2zV4nR85ndc8mbhmpQfY+xDGOmAlyPZOZi1dnf4FW1wojnPieDUiYEfZvGu/Y3lfdxr9fk78DcEFss8l6//WrwhRD/i1yau9iVcnWfvO37sRC4m2szXuHLbQTw/bkVU/d12HDyGO76Yh75vTEP6kDFh0/1cNvwv9HhpSsTHAUJ/tqEG4uw10kAF3iwGE48BCVZ/x6Y9R0IO5IkHV4MzEektIitFJFNEhgR5/VURWWD8WyUi+0yv5ZpeG+1mOd3Q940/0em53zF+aeGT0t/ElJ2Thyd/XoYr3ilcXW4nG7nd83dShB0p7VzEF2zah/NemhJVJvyc3DzbzRZP/rwMt32Wga37T3ZsfnXCKowNM9Ix1N9w9fszC1yU1hiZ6H83ag87Pvs7ur1gPQ2NU6w+vxFT12LID4vx3TzfneMjPy0Jut7E5Tvw7Njlrozc7fP6NNu1OMFGqB4LUQtq53u7ZV9kd7n3f7sIV42YWeB7Eikng5dWj4+PeR9nPjXBgZJQtKy+p/6+lccCEjdvtwg4nh6zDLd+lmGrz9qAETPwzpQ1WLX9EO74fG7IAOvYiVykDxmD96euxcy1u7HD6Ne8xagh8k9tF0gEmLthD9YageifIW46o/Hf74Pnwwx2wxvIzfrrSEb0d3thcsguOPFQwq0di0gqgOEALgSQBWCOiIxW1fwe3ao62LT+nQDamXZxVFXbulU+L/B/WQ6FyQVj5yuVueMQrv9wFt6/oX2h1wKbEj+YthZ/ZRasZbAaOGBm/u3y16pEkwvo/76cF1Hm/ykrd6LzcyfTCdipCYymn0vW3qMFmmPt2LTnCOpXLRvxsazsOnQ8v+/HAaNvRKhAdsTUtdh9KBsvX3mGY2UAost9Fm70sFXwY05J46sxiOyzm7Fmd35akoWb9qNimfCXtd02vu8AcO+oBVFNSROuiT4RjajRJFMFfKlAVm8/iLMaVo14212HjmOPzZuH3DzFgaMnULlsSVuDnaJl99sVaQnOfvZ3rB/Wt9DyjcbNi52+Tv5z6NbP5mDTnqMYt3Rb0H0CwD6jFuqdP9Zgz+FsVC9fqsDr/s97yebCnd6veOdkepV1u5xLlBvKS7+tRLemNWLaRzwHaMV7DuJAbtacdQSQqaprVTUbwEgA/UOsfzWAr10sT9IxX0QOHjuBN0MEJYuy9mPa6l2FOuYHE6y62N+kF0pgp3K7AvtveHVKphXbDlomPAx2Yf1l0RZ0e2Gyo3/PjzabSsxy8hIzrVb6kDHWK0RwFR30VWz9c/wzJwDAaxNX5SdbPXrC+n05K6AT8q5DwQOIcIHZim3huxy894dzk21bva3Hc3Lx/LgVYdOz2PnB8Se99U+3dOsnGbjinRlh+64G0/7piZbnR+Df8tQvy9DuqQlo9OBYTLEayGTjaxUutZFTv++LsvaHPgcMU42+Uouz7I8M3GdzFhjgZEAXeIM9w2jmv+TNP23vy012bg7CBc7+v9VuYmbL75HB/13Yf+QEer48xZX5c6PlZnBWF4D5Fz/LWFaIiDQE0AiAeT6X0iKSISIzReRS10rpgGhqaQBgzQ77kfmzY1fg5QmrojpOpOZv3BfzPhI5ZUswuw8dt+wLYTXK8Mf5Wfl9PxYFubD6l0XTtNv7tan4xqLZwc8LaTysfui+mxs+mI+H35ZuK7TsS2PWhYiT0EYhkRNYm309ayPembIGb00KnQ7BTl84f8qBUcYN22Kj5sXN2iwA+HWJdVeFSK6wvy4p/J2IRrhjBs51G87LE1bZCuasuHVNzXZg5ohw3UwA32jLSSuMQD3KQ85Z72vmnRWmP10wwdJZ+a/vU1fvxJqdh/FGiIF18eaVAQEDAHynquZbs4aq2h7ANQBeE5FTAzcSkYFGAJexc2fkIzkS7VIjAWqwiZbN315VxdEgd8TdXpgUVVgYbgJi/52unfPHf7I4Idpr/5hFWwv/TQFvTL+3/kL/4X+h6cNjYdfgUQsduxw++tMSzDR1WF+x7SDmORAEu+38l6dEtP7/jCm+7L5vqy1G79r9IRr4+dwCz1dsO4jfAmpq5m3ci3tHLbDdydrOsWPp2+YGf21huGmTcvIUV743A9NNI17nb9wbVQf0cIlwvXBzEYtEFt/NOYUDuxc4MaPLv760NyXW8q2ha6b+tyB03sUk/0pFxM3gbDOA+qbn9YxlwQxAQJOmqm42/l8LYAoK9kfzrzNCVduravsaNWJry45FtHc0wYMykzA9lLcfOI7/fBvfeQcDHQvRdBQv//5qXtg7qc1xnl8w0OczN2DAiJnhVzRx+k7Zbod38+jYSJuy7x65ANk5efkjTcOZGGXWb7t+mJeFmz6ajR/mb8aBo6F/8Pzf5a9mbcQD3y0MWcsRLKHlwk37cOV7M/CXjVQf5sAlnokwdx06jtnr9mDwNwvyl1329nR8/Nf6QuuG+wSfHlP0ZmCIh/FBantDmb9xb9DBBPOiTIobbUuP2f9szLMcjWimtPOzM6rfjkhvSN3i2oAAAHMANBWRRvAFZQPgqwUrQERaAKgCYIZpWRUAR1T1uIhUB9AFwAsulrXYmO5Qjig7P0CR8lpTKADk2gjmQnWeX7J5P1JT7F8MI71wRyJcTUZenuK5X5ej3xlBex8UECo/UbNHfg1djhCf876jJ1CmZGrY49t17zcLUbG07zJnt1kukqDDfD75pwIbbDHbhRU7TUKrtx9E01oVbO1vxprd2HM4G31Pr2O7DE7kJgt0MEQqgplrdxfbmSLW7rTuznIgSI2ZP/nt5e0Knpd2aqtu/7xwl41IrrNWN1mP/W8pOjWuhmY2v5PhrAnxntjV9OFfseKp3hFtE+yvC/X5xJNrNWeqmgNgEIDxAJYD+EZVl4rIUBHpZ1p1AICRWrBe/TQAGSKyEMBkAMPMozyLm8PHc/FTmOre/HXDJLm9xqHs6t9kZIVfqQh4OsR0Uf6QK9S0RZe8+Scufj10RnWzDNOAjng3Cy3Zsh/vT1uHQV+Hv+hHl2Xb947ttuh8D/g6kHd3KY3JAxZD/GPhVP+mcPqEycpvdvX7M/Hvr+w1M4WiCkxesSPqIOrukQssX3v5t8iy0VvlenRyRgW7U+z5RTv3ZrQpW6w+h1DnYrBUTsFS31j58E/rGVm27j+GLfuORtWPbsv+o/hylvN5zCJJ8u51btacQVXHAhgbsOyxgOdPBNluOoA2bpbNaet3HUZaiRScUrmMI/s7cDQnvz/OzkP2cz7FYwodO6K5bj3wnfM/nrFab2NS+0hEknpjyZYDeH7cCseOfeNHoeds9SfeDJcSA0BUnT/8P0rLt578oQ2WG2q3w8lX/ZweJexUkspfFoWvOQtsjv/EYhDKByF+TIHIm7Ru/uRk8uJIz+lQiUYDB1K8NWl1yC4Sr04sPBhqysoduOnjOXjj6nbod8YpkRUujJw8RQmLGu9Y8+EN+zW6czoRffhW7wjdRyzaGteZa/dg5trI+yub3/q8PEVKBK0SdoyxcS7Gi1cGBCQ1gaDHS1NwzrBJ2BmiuScSD3y/KGi/lqLMzo+UXV6dCzOS5LY/L9zimyYmTKoMuxftZVtDp33w53izsz+reVgjZRVkeN2J3Dw8HUNHanPTUqhs9IW3i6eCRws3kCgWL/22KuLaWP+UcUuD5PGKlr+G7o3fV4c9D7zXCcNZa3YcwuLNsc1OE8jJy/LU1c4NApzp0OwiTmJw5gBzbqEOz0zEle/NCLF25BYkwai+QMk+UsuO9UaTStiBHTEKV9sRmEfOaeYgZO/hbNz66RzHbkKsBGYTTx8yxlN3tc+MWR73pv09h7Md6/Qcja9mbUzYsf2c6Jca6tpknrA8Xn1gM3ccxI6Dx7AjzJRGR+LcRy87Nw/7QyQQfntyZuRNuw5GZ04M7vIX/0sPfLcDudqsWVwEdiAON6dZpD6NwxxjFDl/f45IEkYmI3NT2Yd/rot5hKWd6/kdXxTuM+VEPyqnLA9TC+mGSKdzmruh8HXokZ8WO1Ucz4l3bflWhybSvuCVqRABvrm9c8j1pkYx8XestoT4G2et24MLTqtVaHnIbhHF4KbdKaw5I0sebRmkJOUPyuJ9fQ42Ai7RnE5BE6yWZ+jPhZtdrfpQTlm5AxOWbS/QtFiUa7+zc/ISWgvp5x/pnazvdbBBCqt3HLLsmB/NtHCRiDRA/2PVTtw9MrYZStzCmrMITF2105UUEkWRF641WXuP4OlfluO1AW0TXRTCyelloh3lRpFZGMF0QVv3H/PMYCK7/LMdRDMwo/mjv6JauTT8cmc3y3WiyQcWaULXH+edbBoPlXrEq9bsDD4g4LTHxsW5JNELl/g2UVhzFoEbPpqN96Y6N0+e123YfdjRoerxtHDTPjz9y3KMW7oNk1e4m+g0UpFOK+TVwQ3J6PH/LcF+B5qhrebiBELngEsmgbUi5u/hKouZHdx2IlexcfcR5OTm4aXffCM4v57tm2YqklGQqr7PsNNzv1uvY3GLGWoAR6jUE8GYu0T885PkCo6j4eS17JPp67Aoa59zO/QY1pwlyCAP9Z+xsn73EZz74pREFyMq1384G6fVqZjoYgTlT1bqVYfDTJ4dq0ROfP/pjA3ILYI1d8Ey/Idi5y2YHjB3pHmb8XHK7xZM9xcno25AyqK9LqVfCZSxfg/+cLDvV7jUJ4nkxmniZHP+X5m70e8tb19LY8GaswRxMm0EBXcgqkSpFGqAgxMj2ALnvoy3cNM4JZsdB45F3Dk9mto9L83gEdh3yY2AO1iy1r+/6+xIfHLWZ0Vo8ByDM3JFIkazBfJfwN2cRNgr9h85kd+ni0JbsS3x300nJaIm8OUJhZPCJtIfK50fyfj9vOIxC0osbCWsdtC3c0N/Jq947HsZCzZrUpHnxrQ9XnPm0xOQm6dYP6xvootCRVSoabcS7T/fLkx0EYocO/3D2ALkHtacEXmc2LhKxvsOlrxjR4RzQkYrXvOIkjcsdnDmBYocgzMij0tE8smibNX26OYD9Kq7PJqniZJbUU+u7XUMzojItsAJqynxIpmbk4iSA4MzIrLN6anJiIioMAZnREVIjgempCEiotgwOCMqQpo8/Guii0BERDFicEZERETkIQzOiIiIiDyEwRkRERGRhzA4IyIiIvIQBmdEREREHsLgjIiIiMhDGJwREREReYirwZmI9BaRlSKSKSJDgrz+qogsMP6tEpF9ptduFJHVxr8b3SwnERERkVeUcGvHIpIKYDiACwFkAZgjIqNVdZl/HVUdbFr/TgDtjMdVATwOoD0ABTDX2JYT+xEREVGR5mbNWUcAmaq6VlWzAYwE0D/E+lcD+Np43AvABFXdYwRkEwD0drGsRERERJ7gZnBWF8Am0/MsY1khItIQQCMAkyLdloiIiKgo8cqAgAEAvlPV3Eg2EpGBIpIhIhk7d+50qWhERERE8eNmcLYZQH3T83rGsmAG4GSTpu1tVXWEqrZX1fY1atSIsbhEREREiedmcDYHQFMRaSQiafAFYKMDVxKRFgCqAJhhWjwewEUiUkVEqgC4yFhGREREVKS5NlpTVXNEZBB8QVUqgI9UdamIDAWQoar+QG0AgJGqqqZt94jIU/AFeAAwVFX3uFVWIiIiIq9wLTgDAFUdC2BswLLHAp4/YbHtRwA+cq1wRERERB7klQEBRERERAQGZ0RERESewuCMiIiIyEMYnBERERF5CIMzIiIiIg9hcEZERETkIQzOiIiIiDyEwRkRERGRhzA4IyIiIvIQBmdEREREHsLgjIiIiMhDbAVnIlJORFKMx81EpJ+IlHS3aERERETFj92as6kASotIXQC/AbgewCduFYqIiIiouLIbnImqHgFwOYC3VfUfAFq5VywiIiKi4sl2cCYinQFcC2CMsSzVnSIRERERFV92g7N7ADwI4EdVXSoijQFMdq1URERERMVUCTsrqeofAP4AAGNgwC5VvcvNghEREREVR3ZHa34lIhVFpByAJQCWicj97haNiIiIqPix26zZUlUPALgUwK8AGsE3YpOIiIiIHGQ3OCtp5DW7FMBoVT0BQF0rFREREVExZTc4ew/AegDlAEwVkYYADrhVKCIiIqLiyu6AgDcAvGFatEFEznOnSERERETFl90BAZVE5BURyTD+vQxfLRoREREROchus+ZHAA4CuNL4dwDAx+E2EpHeIrJSRDJFZIjFOleKyDIRWSoiX5mW54rIAuPfaJvlJCIiIkpqtpo1AZyqqleYnj8pIgtCbSAiqQCGA7gQQBaAOSIyWlWXmdZpCl9y2y6quldEapp2cVRV29osHxEREVGRYLfm7KiIdPU/EZEuAI6G2aYjgExVXauq2QBGAugfsM5tAIar6l4AUNUdNstDREREVCTZrTm7A8BnIlLJeL4XwI1htqkLYJPpeRaAswPWaQYAIvIXfHN1PqGq44zXSotIBoAcAMNU9SebZSUiIiJKWnZHay4EcIaIVDSeHxCRewAscuD4TQH0AFAPvjQdbVR1H4CGqrrZmMdzkogsVtU15o1FZCCAgQDQoEGDGItCRERElHh2mzUB+IIyY6YAALg3zOqbAdQ3Pa9nLDPLgpHUVlXXAVgFX7AGVd1s/L8WwBQA7YKUZ4SqtlfV9jVq1IjkTyEiIiLypIiCswAS5vU5AJqKSCMRSQMwAEDgqMuf4Ks1g4hUh6+Zc62IVBGRUqblXQAsAxEREVERZ7fPWTAhp29S1RwRGQRgPHz9yT5S1aUiMhRAhqqONl67SESWAcgFcL+q7haRcwC8JyJ58AWQw8yjPImIiIiKqpDBmYgcRPAgTACUCbdzVR0LYGzAssdMjxW+5tF7A9aZDqBNuP0TERERFTUhgzNVrRCvghARERFRbH3OiIiIiMhhDM6IiIiIPITBGREREZGHMDgjIiIi8hAGZ0REREQewuCMiIiIyEMYnBERERF5CIMzIiIiIg9hcEZERETkIQzOiIiIiDyEwRkRERGRhzA4IyIiIvIQBmdEREREHsLgjIiIiMhDGJwREREReQiDMyIiIiIPYXBGRERE5CEMzoiIiIg8hMEZERERkYcwOCMiIiLyEAZnRERERB7C4IyIiIjIQ1wNzkSkt4isFJFMERlisc6VIrJMRJaKyFem5TeKyGrj341ulpOIiIjIK0q4tWMRSQUwHMCFALIAzBGR0aq6zLROUwAPAuiiqntFpKaxvCqAxwG0B6AA5hrb7nWrvERERERe4GbNWUcAmaq6VlWzAYwE0D9gndsADPcHXaq6w1jeC8AEVd1jvDYBQG8Xy0pERETkCW4GZ3UBbDI9zzKWmTUD0ExE/hKRmSLSO4JtiYiIiIoc15o1Izh+UwA9ANQDMFVE2tjdWEQGAhgIAA0aNHCjfERERERx5WbN2WYA9U3P6xnLzLIAjFbVE6q6DsAq+II1O9tCVUeoantVbV+jRg1HC09ERESUCG4GZ3MANBWRRiKSBmAAgNEB6/wEX60ZRKQ6fM2cawGMB3CRiFQRkSoALjKWERERERVprjVrqmqOiAyCL6hKBfCRqi4VkaEAMlR1NE4GYcsA5AK4X1V3A4CIPAVfgAcAQ1V1j1tlJSIiIvIKV/ucqepYAGMDlj1meqwA7jX+BW77EYCP3CwfERERkddwhgAiIiIiD2FwRkREROQhDM6IiIiIPITBGREREZGHMDgjIiIi8hAGZ0REREQewuCMiIiIyEMYnBERERF5CIMzIiIiIg9hcEZERETkIQzOiIiIiDyEwRkRERGRhzA4IyIiIvIQBmdEREREHsLgjIiIiMhDGJwREREReQiDMyIiIiIPYXBGRERE5CEMzoiIiIg8hMEZERERkYcwOCMiIiLyEAZnRERERB7C4IyIiIjIQ1wNzkSkt4isFJFMERkS5PWbRGSniCww/t1qei3XtHy0m+UkIiIi8ooSbu1YRFIBDAdwIYAsAHNEZLSqLgtYdZSqDgqyi6Oq2tat8hERERF5kZs1Zx0BZKrqWlXNBjASQH8Xj0dERESU9NwMzuoC2GR6nmUsC3SFiCwSke9EpL5peWkRyRCRmSJyqYvlJCIiIvKMRA8I+BlAuqqeDmACgE9NrzVU1fYArgHwmoicGrixiAw0AriMnTt3xqfERERERC5yMzjbDMBcE1bPWJZPVXer6nHj6QcAzjK9ttn4fy2AKQDaBR5AVUeoantVbV+jRg1nS0/F2qDzmiS6CEREVEy5GZzNAdBURBqJSBqAAQAKjLoUkTqmp/0ALDeWVxGRUsbj6gC6AAgcSEDkmpQUSXQRiIiomHItOFPVHACDAIyHL+j6RlWXishQEelnrHaXiCwVkYUA7gJwk7H8NAAZxvLJAIYFGeVJ5Jp6VcrgpnPSE10MIiIqhlxLpQEAqjoWwNiAZY+ZHj8I4MEg200H0MbNslH8Xd6uLn6Yvzn8ih7wj7PqQdoLPpm+PtFFISKiYibRAwKKlB7Ni0e/txf/fjoua1cXy4b2Qp82tW1vV7FMSRdL5SwRNmsSFScNqpZNdBGI8jE4c1DPFjULLevSpFqhZRVKB6+wnHxfD6eLFFa3ptWDLj+jXiXLbRrXKIdXr2qLsmkl8Pa1Z1muR+5rWI0/KMno+//r7Mp+q5ZLc2W/sSiblproIhAlHQZnDvr7WfULLStTsnAglpYa/G1vVL2c42UK56V/nBF0+d/OOCXmfdetXCbmfRAVRW3qVk50EeLGiwEjkdcxOHNQmbRU9HMgqPGLtVYk3cb2Vo13JS0CSLtKpAi6NilYK3d6iNo4Kuz9G9rHvA8GyJRoydJDQKGJLgJ5SLUE31QwOItS44BarnXP9Qm6XrALk92L1ehBXXF1xwZBX/v3eYVy8hZSrXwpy+3DGdCxcC2gn9q4hqWkSKGL3eVn1ou4HGc3qhrxNlb6tz0FzWtVcGx/bgsVH0+9/zwAQOtTQge8t5/b2Mkikce9bFETXtzUrlga64f1LTb9gMkZ5Uu5OkYyIgzOHOJUB/JHL2mZ/7hSmZI4tUbwps4yJe3143ju8ugGvZYqYb3/6uVLRby/966Prm+a3bf17WvPDLvO6wPaYezd3dDY4j31e/PqQvmOAQBTXO4TOPeRCwo8F8t6TaBO5dL48V/nWDZLm1ndOCTSpW2dq2GO1AWn1Yppe6t+mnbd0LlhTNuHcl6Qfq92RfN3XWHjhsvOzVwwr1zJQJPiq7TpdzXRNb4MzqIQqrqzftXYmpFu6dqowPNIgr7OjQsPPojFq1cFvzhG+qV9/oo26NXK/qjOaPRpUyf8SgBSUwQlQiSYnfHg+Zb97dKrl3P1hK0WYdDbrkEVlLHR2VpEcEb9ylGWKrHOC6j5OOfUk9/xy9sFm6rXfT2aRx8A+SX6wh/MKZW81QQeS7eOaN7flnUqRn08IqcxOIvCE/1aWXbWuueCZpa1XU5pa/FD+/XATrb3UaqE76MvG6Ia97J2kTdDJrOzGlZBnTA/UAM6RNdMnGidHGwedsKpNcrbWi/w5sTuDUizWtb7rxRjShcPxlWusBpVbuZkkHlle+evNxe2tK4lveC0gkF2vzMSE+yTl3in3yGDsyiE+vhKpqbgghAXBJ/Ir2g3d0nH9/93TsTbWXn0kpaY/+iFUbWx26rhceg77kaNWzTNLP676sf/1jLkev6g122RfoPu79XclXJE45G+p6Fq+cg723YMCDCtagMbVC2L0YO6Bn2tW9PqqFim8Hc+khGF0QYkVcr6gsLerWsj1YWqMyd2WSBvYZx/p9rWrxLydatR7qFc07EBljzZy+LVgm9Y67oVI8rbSMmtb5s6YdK8JPY2jMGZCwL7Ci0b2gvLhlpdIMLty8ccUDhxEU5NEVSx+EG6vbt1J/LfBnd3rNPk+Hu6Y9w93Sxfr1SmJG46Jx2Ln7iowPKn+rcq8DxcwBQo8DcnklE5pcP09UvxYnsVgBIxjr510q3d7A9SUNMX/+xGVQt8duYmTrOpD5xn+TlVLFMyv1nbXKsy/p7uGD2oi+1yReL5K3z9PpvWqoD1w/rinFOrxzR3q1WN1sN9Tot6n36vXNm2wPOWdSpiyMUtCiyLdBSbqr2R4+FGS1aLIqAXkaDXq9u6NUK7BpULLbfqTzvtgfMiPjZZS/XI3MVu3CQ5xTtX7CJKAJRNK4GyadEFNFbfnSY17TULWQl1coTq53ZKkNQMVslz/9m1ESqVKWnZSbl57QpoUdu6n8f8Ry+EiKBC6cLNUGPvOhnU3dylUaHX7bq7Z9P8wQoaokqtVMnCp0qwEbP+H5iRETQx2+FEWo146h+kw3+KAC9ccXqBZeYfw8DUK4Gu6+RsR/ozG5ysqalRoRROr1fZ1nZuXs7LpaUW6ndqVr5UCZwXps+bVV9ROwKD2rF3d8Md5xb8ngcbUPPC308vtMzsNFN/rt8Gdw866CbagQPReLhvy0I3UpXLpuHBiwsHuL/c2RX1k2z2gL+fVbiJuGq5NEdbX2JxcxLMWxyvVhArDM6iFOoCXTrIDzkAfHxTB3x3RyyZwU9evXq3rlMgQPGrVdFep/LLQnSmrlOpdKFl157dAOuH9Q16F2qVPLdF7YpY+PhFqFmh8P7ssKxdEEHLU0J33vX/6HdIt24qmTC4OwZf2MxWTeTwa8KPBjU7o15lvHvdWRgR5SjVQOZanrqVyzh652mnj2Q5B7K8N6tVAVd28KVo8dculyvl2+/Zjarii1vPttz2yX6tUKviye/Rnec38VDvkNDya9JtFHjp0N7h9xfmo7+sXT1HpiJy8v01lzk1RaJKcu128FapTMmgA2xa1/V2fsZgtZLBztcU8fWrddKMB8+Partbutm7oZ71UE880jf2GuFohLoexQODsyhYNaf43XHuqUE7JJ/Xoibap8feMdt/nQsWoPzwry64uUt62H1YJZl9uM9puD5IDcUzlyXXPPTdjbQAzYLkNQtVQ2YlWI2h2R/39yg0JU/v1rVxUSx95ix+hL++rVPYUbz+hL81K4QP1tOrlcOYu4L30fLr1Tr6v+PXuwvfRAQ2YYVrDo51FHSBY8f4Ix/pqFonhXqX4jkf7JT7ehT6XO2kdTELrA02fyz3XdQs2qIBSHRvoeBC1YgC0c+kEO7a5NezRWQpZMqXKhFVepWhAd1OggmVJsisVsXS6ORwFgK7EjFjjxmDswisfbYP1j7bJ2yer9IlU3HvhdYdsJ28hgb2t6pbuQz62kwrEUzP02rG1B/Ga8xNV4Fi/RzMF5iG1crhrIbeGBGZViIFP/6rCz6+uYPtARXR9CM8vV4lPHd5m6AzPwRr1gwlXnHF304/eW5Ee0w7OQZPqVS6cO2VzeO1MWpqgp2GgYMirHbvdrb79OrlCjRVAsGb0gCge7PgP/ChRtTabWJOJuYclkDhcy7a2vBgNxulA2rOHujdHE9f1jqi/UZ7St7QOT3sOlbfT3MLQfdmvjQ6/tHVkYzmTUtNwbnNkjsBMYOzCKSkSMICF1XNvzNOM7WFx9LfiqJjlcokFk72UfvzgfOQmiI4r3lNW7UpF7UKfUdtdZFLEcHVHRtg9KCuhX6ouzbxbROuljmQ2/08erc2BWeuHikyretWxCjjO3Bpu7r4/T/nBn3fU1Ls1jlELjDthFUNc6Q1j4POb2prP3b/rq9ibG5yeq7Pb24/WWO+5ln7CZ+XPNkrPyCrX7VMzH+X2T09C9Y81q5YOuYp+ewINVgk0mTY/p/a+lXL4sd/nYOh/VvjGZsBZuMa5fBQuAEy4qXEGYUxOItSvJoQzEdpW68y/n3eqXjtquAZ7KNlzq4fz6YRp5mTy5Y3RrQFG7UXeEL6Z0OoUtbeRdvf7Fu3Shl8d0dnDL4gdBPMu9edaTlowg01Kwbv43fJ6cFrVK8Kkbtt/bC++PSfHcNexc4MMvLtz/+ehw9v7BB6wwBtXOzf06mxr9Yp1guyG6dI7Yqlcbap+cacB+6ta9oVGjEZTqHARwrPs5oWEAj7UwD5O/c3rOZMs84plUqjXZg0GYBvJK1Z3conax7rVCqd35/W3C/MC3PHhqrNDGfGkPPx2+DumPbA+WhqY2q5elXs/b12klP71bDR9cGuUCNqRQS1La5N+etYLG/XoApKl0zFNTanIxQRVC4bWz7DRGNw5hL/lzQ9RLt14+rlIpoMPCVFcH+vFqgdpMN+KOPv6R7y9T5t6tga6u6kq9pbz90ZLfN7/d/eLTDk4ha4OGRfKd+loNUpFfHUpa1t95m5/My6+OTmDhjQoT7ap1fF3RcErxnw6926Tlz6L7xz7Zkh5yJ95cq2ltN5RVMfYx619/jfWuHr2wrW/tWrUjaiHwkA+PDGDoX2Y3bt2Q3QuXE1W00nZpPv64GRAwv2CYw2yKpsI4h38o68bFpq/vdHFQUGRlgeP6AA1cql4e6eBb+nZdNSg47sbFHbFySYm9msrg/+VATh+sLdauoAbnewQu1KpfO7aAy+oFnQDyzWUeuRqGCj6d+qtvHas4MHFTUrlg7aL9YsXNLkaJuwpz1wHn4b3L1AzV+sQk37Z0fXMH3czJUHq5+5OP9xWokUDO3fCg/1OXkTU6N8qQKD84KlTvEyBmcu6ZBeFZ/c3AH3XVS475n/6/X1wE6WyTKd1Lx2hTDJ9uJfvft8mKH3odj5TS1XqgTuOPdUW83QIoLrOzW0zPsWbP0eNpsMneQPhlJTgx/34jZ1MCrEhTatRAqutnnnacczl54M9NJKpFhOf+Mf/XuljYC8UtmS6GxqCvXnZ/MHj9XKl8LXAzs5ercfqbMaVsEHN7SPuDYrUv6/sUzJEgW+8/de1AyvXHkGvrjl7AI/RnZdcWY99D29Dt6/oT1a1rF3czh+cPAbvCEXt8ANnRuiX5g+huZzJVTzWmAH9EiD+2DHc8qv93TDa1e1zX/+cJ/T8MUtBZsira6j/n6KrevamyLqtava5geDCx8/mefRyT+rftWyaFarAqobFQmFgkAJ/z4GxqKXGlkArOZc9SeAtroZPOdU+wMQzN+jVU9fjBs6p+dvL/BVZqx46mKLrUPz17InEoMzF/VoXrNQ00Gk/CdHqODp9QFt8cudJ4M8/4CFYE1NYY8XZJmdVAu3hhmJFE40ZU1WFW1MixPM17d1wlOXtnalKSfc3be/mdgcgNn94axcNg3rh/XFP6P4jjxzWWvc0rVRVKPGptzXI2iner9Yem9d0LJWoYz1wXJ3ASeD6n8EdJgPl9j0iX6t8MLfTy/0Q1GqRCouP7MeujatXmD0d7gfbv9nnCK+1DAdIhg5blUjUqVcGob2bx1zjUlYHuhtUa9K2fzgAwBu6944bE1PoFED7dVSXdquLsbc1Q2vD2gbdt1Yaw8rlC6J9cP64jab6S1C8ffHfdli0vqPb+6IRy9pidqVSgcdhGT+Djv9kd+UBLnVzBicRcn/xbnizHr4/JaO7h3HnyIpxG9n/7Z1C+TiSa9eDr8N7o7/9o79zj7zmYvx2+Bzw673iGkkUof0KnjrmuA/VDedk16oKWXSf87FZ7eE7gz78j/OCJuZ3G6KDP8dYqgJ0KN174W+/mehgvIz6lfGpTZGMwaWrlbF0kHTnMTDf3u3wEN9WuC27r4LeEmL2jun1axQGo9e0jKqGQ7Sq5fLTx4aa2ntpAewUqNCKawf1hf/CKg5rBgkubJZ2bQSuLJ9fcdrgcy7szN/ZiA3atmb16qA3q1q5w8IsTvTRiyzlYSad9Mt5YzyNrURUDWoVhb924ae7/Punk0x6LzQ3SoA2ArEI/2eRTN4p27lMvkpRSIdLBSrcO8lELpWN968U5Ikdfu5jdGtaWRDdged3wRA7BMwh9KsVgVHpuwpkZoS8RDvb+84xzK/1xP9WhWaUL1xjfL5F1mru5srzqoXU64ts/euOwuP/61lyP6A0RrY/VSsH9bXM9OTROOunoUv9uVKlcDA7qciNcX3nYopf5tJPLPCxyJYHzcvZI23+pbZvVEJliOrTiXfsr+dEX1KHjvMJXz6stZIK5GCYVecjn/1ODXoD7c/oDHPGPLMZa2jzonWpGZ5rB/Wt9Dy4decGfENt/9Gz/y297IYBZ35zMUYF6YfsF1Na5VH7UqlsX5Y3/zz9qObCuaPWz+sb0Tf1WuM/nHhrmCxDnIK19Umnnoas9i0OsU7CYcZnEXJP2qmdBTV+Td0Tsf6YX3DztMYTw/3OQ1Vy6VFPNjALNb+TOuH9cUT/VrhvevPwotR9Emz+ztfs2Jpz6Ug8QdzTmTij0WDqmXza/+C8XLIWb18WsjBBH7+UX/VK6ThktPrBP0hnnhv97CzQlzYspbljB92YiO3c5FFq0aFUljxVG/cFsEcqE6pXr4UHujdImhf0acvbY0vbz27QDNe5bJpBVJ1/KtH4SnVItX39DoR33AHq3R64+p2+YHSBaZaumhuePOPA7EcXHBPz6aY/VBPnB9hslnLY4WpSQsW2EdS+VavSnQ3N33b1LHsQhDO/b2ao5Upebs/N58/eHWjNSVazsxgXQy9NqAdpmfuQoM4j3J0y0WtYsxmD+C5y9tYjgaMhFXi1GhrWcbc1RV7DmfHUCJ33dWzKc4ykuUuHdobN3w0G1NX7UxwqeKjctmS2LjHmbQNDauVKzCYwMotXRujbuWy6NOmdqFaXL8mNSugSc0K+PdXofdl7vMVS//ScImtGxupNXo0tw4awv3tkZw/Xrlx9I8crVe5DEqXTEWXMPOvphvfoxs6F2z+H3dPN/R+bVrQbb69ozMqO9SKYQ64S5VIxfktagWtnYvFM5e1wd4j2Ri7eFuBfpMpKVIgjc4/uzSynErQrtrGjUzdymWwed9RiNj/Hr0+oC1+nL8ZU1YGv5YFC+TshEbDrw190xSMP43Qv89rggZVy+LOr+cDAB67pCUe6N0cuXmK1BRB16bVMW7ptoj37wZXgzMR6Q3gdQCpAD5Q1WEBr98E4EUAm41Fb6nqB8ZrNwJ4xFj+tKp+6mZZI1WpTElcHEMm/kh59S47ESzvzizeIi9VVQcTqqYqUX6OZhSx6XOx2yet1SmVcM8FTSMapWXFblNeaoqgr0XOt1hceFotXNepAb6YuTHibR8LmOkjUJOa5bHgsQsLdYXw126c2aAyWtQ+WSNwas3y2LL/GO48vwnenJRZcBsX6z/Pb1ETk1bscGx//+zSCO3Tq9pO/FwmLTVoMGR+bwJFMjDCiu899X3/7u/VHNk5eVHtZ/w93XEit/C2n/6zI278aHZE+wr3nbJiPo2e6NcKnRpXQ/PaFdD3jT/RvFYFrNh2sNDglmD6t62Lrk2q46ynJ4ZN/OsP/tyw4qneln3JUlIEZdN8YdCjl7TE7HV7ANibBcRtrgVnIpIKYDiACwFkAZgjIqNVdVnAqqNUdVDAtlUBPA6gPXzf+LnGtnvdKq9XeaeSNXl8G9Pk8u5rVqsCdh06DsA30MGL2kSQf8+vUpmSePDiFrioVe2IOhc71Qzjhsf/1hJjF28Nuc7lZ9bFD/M2IyVF8O/zmkQcnFUqUzL/ByKUYPnVTq9bCbd2bYSbLObTtVMj+Y+z6tma3PuLW87GdR/OCtkR/P0b2qPTc79j58HjYfdnZvVtSUmRiGbk8EIO7X+f1yTqbZvXDp7zLL55KE9GZ2XTSuDyM+th2ZYD+cvMwW/18qVQs0Ip7Ijw8w4UrNbZ7jWkcZi+w5HUAndIr4J7LmiK6xI08MrMzZqzjgAyVXUtAIjISAD9AQQGZ8H0AjBBVfcY204A0BvA1y6V1VMe6tMCnRvHXpNQXDk9PYvThlzcAvd9uxBA8Pn0zm9eA1NX7cxvokkmt58be58fJ0XaFP7OtWcWqJ26uUuj/P6JlcqUxP6jJwpt88qVbfHKlW0BnByBeWm7umGDOiekpEiBkdKB7Py8vWjzBqFLk2q46/wmuDbED1dqitgexVfV5owcycStAS7xGDjjj4X8aVH6tAnfzSWtRApmP3wBLh3+FxZs2hf1setWLoN1uw6jVIQ1VgsfuwilTE23/lyV0SacFRHcE2bGl3hxMzirC2CT6XkWgGD5Eq4Qke4AVgEYrKqbLLYNPw62iBjY3Vs/cMnijavb4Z0pa9DQA6PoQgk3XPvGc9Jxabu6tjLRkz12a1RCdVUYc1fXAjUIwZQrVQLLhvZC6RKpcQnOwilXyvdj17NFLVzYshbe/WMNBp4bXUd/EcG9QZJqR6tS2ZJoWrM8Vu845Ng+7XjFIgdXTOJUY2cntVKsSpdMxdxHLnA1m0Cgt65ph78yd0ecw7FS2cApv8rg17u7FZj+LFklekDAzwC+VtXjInI7gE8BnG93YxEZCGAgADRo4Fzmcy/xJ/8MlxOpOLG6MLWuWymqzqKhNKxWFht2H3F0n+H45oXzZmDm/3Gwm4eqKKlXpaytEWZ2mijjpWxaCcx8sCeqlU9DydQUTLk/dOLbeAucTzNW5WzkPevRvKajxwR8UwW51WcqFLdOw2oBA1T8tVNW8/bGqnLZNMf6gZ5mMVNJsnHzKrIZgDnrYj2c7PgPAFDV3aanHwB4wbRtj4BtpwQeQFVHABgBAO3bt0/aHvP3XNAUR7Jzg77W/4y62H/kBAY4NO3OD/86x3bHaa+5v1dz5OTm5Q9/fuGK07F0y35Xj/nLnV1x8FiOq8dwwikxpEABTubcOy/EaEAAuKhlbVzfqWHY+UTjwT/C8eqO9fH17E3o7VAevKImlvQ4yWLivd3x2sTV6NEsshQYThl1eydMz9zt2ihXJ6/YQy5ugRfGrYhom1NrlMcrV56B81s4F9j6EyC3b1jFsX0WJW4GZ3MANBWRRvAFWwMAXGNeQUTqqKq/7r8fgOXG4/EAnhUR/6d2EYAHXSxrQoVq405JEdzkYE6u5rUq2Lq79KKq5dIK9I+5skN9FIz/nVehdMkCSS9j0atVrZg7zgYz4vqzcHq9yjHto3LZNMx48HzUCJPSIa1ECp66tHVMxwJO9jfy5xyLah/l0rD4iYtQLq0EHu7bMuE54sjn/BY18dmMDa4e46Zz0vOnxQJ8qU/eCpOXzk31qpTFlR3c707hREXZHeeeijui6Bt6ucV8mdG6uUsjlEhJwfWdg/dhLH518wW59iutqjkiMgi+QCsVwEequlREhgLIUNXRAO4SkX4AcgDsAXCTse0eEXkKvgAPAIb6BwcQJav3rj+Zufu2bo3x+/IdYfM22eFUtn5/Zvh46N26Nl4f0BZ9YkxH4w+cY5nGpyj6R/v6mLZ6l+XoPzc9dklL/F+PU9H5uUlh1422Fv+JftFPp5WMAt8n/0AiJ3Om1jea7Bs6ODK0pDE4JNj8nyVTU6Kab7e4cPWKpqpjAYwNWPaY6fGDsKgRU9WPAHzkZvmIEqV13UpY8mSvhBx7wuDuuPDVqQk5tp+I2JrrjqLT74xT0O+M8PO3uqFEagrqVCqDifd2x7wN+2xtk0xdGD+5uQOWbz2YkGP700s82a8ValYojQtOcy4NzSWn10GNCqVwdqPY8775VSxdEp/f0hGn163s2D6LC95uEhUzTWqWR7Vyadjt4VkTnNK1aXV8NWujY03TTqpQuiQaVy+HB3o7NwLSS/yzLPh9+s+OKOmh6XGi1aN5TVcGFUSiWvlSUSeZtSIi6NTY+cnII50Ki3wYnBEVMyKCuY9eiPQhYxJdFNc92a8V7uh+qidz36WmCCbFOHl0Mjk3QZ31yX3JOcTM2zjxeTHxze2dcWvXRijLTtNJpVcr72bPTwYlU1OKzPy3FH/n2JirNR6SJfhJhnrRM4zBU/0T1OxvF2vOionWdSvZmqKFvMU8iKC4qVMMUkBQ/AzoUB89I+ijtfTJXjFNZu+GZAh+vK5BtbKOT0bvBgZnROQ5n/2zY0JGGlLRNeyK0yNaP1lTDlHR4K3bAiIiAN2b1UAtl7KRk3f4p9nhDChEBfHWgIiIEuKpS1vjb2ecgqa1WEtKBUky5VdxAWvOiIgoIUqXTEV3juIMK0ln3ItK/aq+ZNj/1yPyWQyKEgZnREREyaAYVCY91b81alYohVanFI0JzKPF4IyomLqsXV2UTC0GV3siSho9mtfE7IcvcG0S+WTB4IyomHr1qrZY/UyfRBeDiIgCMDgjInJB+/QqAJiSgZyTUsw7yRcnvGoQEbngucvb4Pbup6J6+VKJLgolucbVy+GWro1wXaeGiS4KxQmDMyIiF5QqkcpEuuSIlBTBo5c4O9E5eRubNYmIiIg8hMEZERERRe3C02oCAGpzPlzHsFmTiIiIovavHk1w7dkNUaVcWqKLUmSw5oyIiIiilpIiDMwcxuCMiIiIyEMYnBERERF5CIMzIiIiIg9hcEZERETkIQzOiIiIiDzE1eBMRHqLyEoRyRSRISHWu0JEVETaG8/TReSoiCww/r3rZjmJiIiIvMK1PGcikgpgOIALAWQBmCMio1V1WcB6FQDcDWBWwC7WqGpbt8pHRERE5EVu1px1BJCpqmtVNRvASAD9g6z3FIDnARxzsSxEREREScHN4KwugE2m51nGsnwiciaA+qo6Jsj2jURkvoj8ISLdXCwnERERkWckbPomEUkB8AqAm4K8vBVAA1XdLSJnAfhJRFqp6oGAfQwEMBAAGjRo4HKJiYiIiNznZnC2GUB90/N6xjK/CgBaA5giIgBQG8BoEemnqhkAjgOAqs4VkTUAmgHIMB9AVUcAGAEAIrJTRDa49LeYVQewKw7HIffxsywa+DkWHfwsiw5+luE1tHpBVNWVI4pICQCrAPSELyibA+AaVV1qsf4UAPepaoaI1ACwR1VzRaQxgGkA2qjqHlcKGwERyVDV9okuB8WOn2XRwM+x6OBnWXTws4yNazVnqpojIoMAjAeQCuAjVV0qIkMBZKjq6BCbdwcwVEROAMgDcIcXAjMiIiIit7na50xVxwIYG7DsMYt1e5gefw/gezfLRkRERORFnCEgciMSXQByDD/LooGfY9HBz7Lo4GcZA9f6nBERERFR5FhzRkREROQhDM5ssjtPKMWXiNQXkckiskxElorI3cbyqiIyQURWG/9XMZaLiLxhfI6LjETI/n3daKy/WkRuNC0/S0QWG9u8IUbuF3KeiKQayad/MZ43EpFZxns/SkTSjOWljOeZxuvppn08aCxfKSK9TMt5DseJiFQWke9EZIWILBeRzjwnk5OIDDaurUtE5GsRKc3zMg5Ulf/C/INvtOkaAI0BpAFYCKBlosvFfwoAdQCcaTyuAF/6lpYAXgAwxFg+BMDzxuM+AH4FIAA6AZhlLK8KYK3xfxXjcRXjtdnGumJse3Gi/+6i+g/AvQC+AvCL8fwbAAOMx+8C+D/j8b8AvGs8HgBglPG4pXF+lgLQyDhvU3kOx/1z/BTArcbjNACVeU4m3z/4ZvVZB6CM8fwb+BLH87x0+R9rzuyxO08oxZmqblXVecbjgwCWw3dB6Q/fDwSM/y81HvcH8Jn6zARQWUTqAOgFYIKq7lHVvQAmAOhtvFZRVWeq7yrzmWlf5CARqQegL4APjOcC4HwA3xmrBH6O/s/3OwA9jfX7AxipqsdVdR2ATPjOX57DcSIileBLh/QhAKhqtqruA8/JZFUCQBnx5S4tC98MPjwvXcbgzJ6w84RS4hlV6O0AzAJQS1W3Gi9tA1DLeGz1WYZanhVkOTnvNQAPwJfbEACqAdinqjnGc/N7n/95Ga/vN9aP9PMl5zUCsBPAx0YT9QciUg48J5OOqm4G8BKAjfAFZfsBzAXPS9cxOKMiQUTKw5cb7x4NmIPVuLvmsGQPE5FLAOxQ1bmJLgvFrASAMwG8o6rtAByGrxkzH8/J5GD0C+wPX8B9CoByAHontFDFBIMze8LNE0oJJCIl4QvMvlTVH4zF243mDxj/7zCWW32WoZbXC7KcnNUFQD8RWQ9f08b5AF6Hr4nLnyzb/N7nf17G65UA7Ebkny85LwtAlqrOMp5/B1+wxnMy+VwAYJ2q7lTVEwB+gO9c5XnpMgZn9swB0NQYoZIGX0fHUNNPUZwY/Rk+BLBcVV8xvTQagH90140A/mdafoMxQqwTgP1GU8t4ABeJSBXjbvEiAOON1w6ISCfjWDeY9kUOUdUHVbWeqqbDd35NUtVrAUwG8HdjtcDP0f/5/t1YX43lA4xRY40ANIWv8zjP4ThR1W0ANolIc2NRTwDLwHMyGW0E0ElEyhrvtf+z5HnptkSPSEiWf/CNKFoF38iShxNdHv7L/1y6wtc8sgjAAuNfH/j6OfwOYDWAiQCqGusLgOHG57gYQHvTvv4JX0fVTAA3m5a3B7DE2OYtGMmb+c+1z7QHTo7WbAzfRTwTwLcAShnLSxvPM43XG5u2f9j4rFbCNIqP53BcP8O2ADKM8/In+EZb8pxMwn8AngSwwni/P4dvxCXPS5f/cYYAIiIiIg9hsyYRERGRhzA4IyIiIvIQBmdEREREHsLgjIiIiMhDGJwREREReQiDMyIqEkRkuvF/uohc4/C+Hwp2LCIiNzCVBhEVKSLSA8B9qnpJBNuU0JNzBQZ7/ZCqlnegeEREYbHmjIiKBBE5ZDwcBqCbiCwQkcEikioiL4rIHBFZJCK3G+v3EJFpIjIavqznEJGfRGSuiCwVkYHGsmEAyhj7+9J8LCOr/YsiskREFovIVaZ9TxGR70RkhYh8aWRYh4gME5FlRlleiud7RETJoUT4VYiIksoQmGrOjCBrv6p2EJFSAP4Skd+Mdc8E0FpV1xnP/6mqe0SkDIA5IvK9qg4RkUGq2jbIsS6HLxv+GQCqG9tMNV5rB6AVgC0A/gLQRUSWA7gMQAtVVRGp7OyfTkRFAWvOiKiouwi+uRsXAJgF3zRCTY3XZpsCMwC4S0QWApgJ34TMTRFaVwBfq2quqm4H8AeADqZ9Z6lqHnzTiqUD2A/gGIAPReRyAEdi/NuIqAhicEZERZ0AuFNV2xr/Gqmqv+bscP5Kvr5qFwDorKpnAJgP31yB0TpuepwLwN+vrSOA7wBcAmBcDPsnoiKKwRkRFTUHAVQwPR8P4P9EpCQAiEgzESkXZLtKAPaq6hERaQGgk+m1E/7tA0wDcJXRr60GgO7wTfgclIiUB1BJVccCGAxfcygRUQHsc0ZERc0iALlG8+QnAF6Hr0lxntEpfyeAS4NsNw7AHUa/sJXwNW36jQCwSETmqeq1puU/AugMYCEABfCAqm4zgrtgKgD4n4iUhq9G796o/kIiKtKYSoOIiIjIQ9isSUREROQhDM6IiIiIPITBGREREZGHMDgjIiIi8hAGZ0REREQewuCMiIiIyEMYnBERERF5CIMzIiIiIg/5f6uAdOLgLZSQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Losses\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training Losses\")\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_pred = []\n",
    "final_lab = []\n",
    "with torch.no_grad():\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    for encodings, labels in testloader:\n",
    "        inputs = encodings['input_ids']\n",
    "        attention_mask = encodings['attention_mask']\n",
    "        inputs, attention_mask = inputs.to(device), attention_mask.to(device)\n",
    "        output = sarcasm_model(inputs,attention_mask).cpu()\n",
    "        preds = torch.flatten(output)\n",
    "        preds[preds<0.5] = 0\n",
    "        preds[preds>=0.5] = 1\n",
    "        val_correct += (preds == labels).float().sum().item()\n",
    "        val_total += len(labels)\n",
    "        preds = preds.numpy()\n",
    "        l = labels.cpu().numpy()\n",
    "        comp = l == preds\n",
    "        final_lab.extend(l)\n",
    "        final_pred.extend(preds)\n",
    "        \n",
    "        \n",
    "        for i in range(l.size):\n",
    "            if comp[i] == True:\n",
    "                correct.append(1)\n",
    "            else:\n",
    "                correct.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPrecision, Recall and Accuracy for Reddit Data:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Sarcastic       0.63      0.77      0.69     50540\n",
      "Not Sarcastic       0.70      0.55      0.62     50537\n",
      "\n",
      "     accuracy                           0.66    101077\n",
      "    macro avg       0.67      0.66      0.65    101077\n",
      " weighted avg       0.67      0.66      0.65    101077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_words = [\"Sarcastic\",\"Not Sarcastic\"]\n",
    "class_report = classification_report(final_lab,final_pred,target_names =r_words)\n",
    "print('\\033[1m'+'Precision, Recall and Accuracy for Reddit Data:\\n')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
