{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6w1r6UJfKFp"
   },
   "source": [
    "# Hyper-Paremeter testing, training, and final model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNXyrz9wcv2Z"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "except ImportError as e:\n",
    "    print('transformers not installed')\n",
    "    print('Installing now...')\n",
    "    !pip install -q git+https://github.com/huggingface/transformers.git\n",
    "    pass  \n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "except ImportError as e:\n",
    "    print('optuna not installed')\n",
    "    print('Installing now...')\n",
    "    !pip install optuna\n",
    "    pass  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKMAuh9oczDj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import io \n",
    "import os\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import transformers\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers.utils.dummy_pt_objects import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForTokenClassification,AutoConfig, AutoModel,AutoTokenizer,BertModel,BertConfig,AdamW, get_constant_schedule,BertForSequenceClassification,get_linear_schedule_with_warmup,get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "\n",
    "#Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvnurzgWc0W4"
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab == True:\n",
    "    #Mounting Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    \n",
    "    %cd '/content/gdrive/Shareddrives/523 Project/Data/News Headlines'\n",
    "    %ls\n",
    "else:\n",
    "    MODEL_PATH = '/projectnb/dl523/projects/Sarcasm/Sarcasm_Models/sarcasm_bert3.pth'\n",
    "    DATA_DIR = '/projectnb2/dl523/projects/Sarcasm'\n",
    "    os.chdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8i9XMHhc3xY"
   },
   "outputs": [],
   "source": [
    "#Getting the BERT outputs for use with other downstream model implementations \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data\n",
    "df = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\",lines = True)\n",
    "df = df.rename(columns={'is_sarcastic': 'label'})\n",
    "df = df.drop('article_link', 1)\n",
    "df.head()\n",
    "\n",
    "#splits for training test validation\n",
    "\n",
    "train_headlines, temporary_text, train_label, temporary_label = train_test_split(df['headline'], df['label'], \n",
    "                                                                    random_state=200, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "validation_headlines, test_headlines, validation_label, test_label = train_test_split(temporary_text, temporary_label, \n",
    "                                                                    random_state=200, \n",
    "                                                                    test_size=0.5, \n",
    "                                                                    stratify=temporary_label)\n",
    "\n",
    "\n",
    "#Set max length for the padding/clipping\n",
    "count = df['headline'].str.split().str.len()\n",
    "count.describe()\n",
    "\n",
    "max_length = 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for modifying BERT \n",
    "class bert_for_sarcasm(nn.Module):\n",
    "\n",
    "    def __init__(self,input_model, linear1 = 256,linear2 = 128,drop = .25,mod_type = 'binary',bert_model = 'bert-base-uncased'):\n",
    "        super(bert_for_sarcasm,self).__init__()\n",
    "        # Assumes size parameters of bert-base-uncased\n",
    "        self.mod_type = mod_type\n",
    "        self.bert_model = bert_model\n",
    "        if self.bert_model == 'bert-base-uncased':\n",
    "            self.model_size = 768\n",
    "        else:\n",
    "            self.model_size = 1024\n",
    "        self.input_model = input_model\n",
    "        \n",
    "        self.linear = nn.Linear(self.model_size,linear1)\n",
    "        \n",
    "        self.linear2 = nn.Linear(linear1,linear2)\n",
    "        \n",
    "        self.linear3 = nn.Linear(linear2,2)\n",
    "        \n",
    "        self.linear3_binary = nn.Linear(linear2,1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.log = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    def forward(self,input_values,attention_mask):\n",
    "   \n",
    "        _,output = self.input_model(input_values, attention_mask=attention_mask).values()\n",
    "        \n",
    "        output = self.linear(output)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        output = self.relu(output)\n",
    "        \n",
    "        output = self.linear2(output)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        output = self.relu(output)\n",
    "        \n",
    "        if self.mod_type == 'binary':\n",
    "            output = self.linear3_binary(output)\n",
    "            output = self.sigmoid(output)\n",
    "        else:\n",
    "            output = self.linear3(output)\n",
    "            output = self.log(output)\n",
    "\n",
    "        \n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmnqPuWudBPa"
   },
   "outputs": [],
   "source": [
    "# Finding best hyper-parameters\n",
    "def train_bert(model, params,trial,tokenizer):\n",
    "    model.to(device)\n",
    "    max_length = 35\n",
    "\n",
    "    #Create tokenized training, validation, and test splits\n",
    "\n",
    "    training_tokens = tokenizer.batch_encode_plus(train_headlines.tolist(),max_length = max_length,padding = True,truncation = True)\n",
    "    validation_tokens = tokenizer.batch_encode_plus(validation_headlines.tolist(),max_length = max_length,padding = True,truncation = True)\n",
    "    test_tokens = tokenizer.batch_encode_plus(test_headlines.tolist(),max_length = max_length,padding= True,truncation = True)\n",
    "\n",
    "    #Stacking the inputs as tensors for use in the BERT model\n",
    "\n",
    "    training_set = TensorDataset(torch.tensor(training_tokens['input_ids']),torch.tensor(training_tokens['attention_mask']),torch.tensor(train_label.tolist()))\n",
    "    validation_set = TensorDataset(torch.tensor(validation_tokens['input_ids']),torch.tensor(validation_tokens['attention_mask']),torch.tensor(validation_label.tolist()))\n",
    "    test_set = TensorDataset(torch.tensor(test_tokens['input_ids']),torch.tensor(test_tokens['attention_mask']),torch.tensor(test_label.tolist()))\n",
    "\n",
    "    trainloader = DataLoader(training_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "    validationloader = DataLoader(validation_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "    testloader = DataLoader(test_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "\n",
    "    Epochs = 60\n",
    "\n",
    "    \n",
    "    #optimizer and scheduler for learning rate\n",
    "    optimizer = AdamW(model.parameters(),lr = params[\"lr\"],eps = 1e-6)\n",
    "    NO_SCHEDULER = False\n",
    "    if params['schedule'] == \"linear\":\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 2,num_training_steps = len(trainloader)*Epochs)\n",
    "    elif params['schedule'] == 'cosine':\n",
    "        scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer,num_warmup_steps = 2, num_training_steps = len(trainloader)*Epochs)\n",
    "    else:\n",
    "        NO_SCHEDULER = True\n",
    "        pass\n",
    "    # Setting the correct loss function \n",
    "    if params['mod_type'] == 'binary':\n",
    "        loss_function = nn.BCELoss()\n",
    "        BINARY = True\n",
    "    else:\n",
    "        loss_function = nn.NLLLoss()\n",
    "        BINARY = False\n",
    "    \n",
    "    min_validation_loss = np.inf\n",
    "    total = 0 \n",
    "    correct = 0\n",
    "    for epoch in range(1, Epochs+1):\n",
    "        model.train()\n",
    "        training_loss = 0 \n",
    "        epoch_step = 0\n",
    "        for idx, (inputs,attention_mask,label) in enumerate(trainloader):\n",
    "\n",
    "            inputs,attention_mask,label = inputs.to(device),attention_mask.to(device),label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(inputs,attention_mask)\n",
    "            if BINARY:\n",
    "                output = torch.flatten(output)\n",
    "                loss = loss_function(output,label.float())\n",
    "            else:\n",
    "                loss = loss_function(output,label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss +=loss.item()*inputs.size(0)\n",
    "            \n",
    "        if NO_SCHEDULER == False:\n",
    "            scheduler.step()\n",
    "        \n",
    "        validation_loss = 0\n",
    "        \n",
    "        total_acc_val = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (inputs,attention_mask,label) in enumerate(validationloader):\n",
    "                inputs,attention_mask,label = inputs.to(device),attention_mask.to(device),label.to(device)\n",
    "\n",
    "                output = model(inputs,attention_mask)\n",
    "                \n",
    "                if BINARY:\n",
    "                    output = torch.flatten(output)\n",
    "                    loss = loss_function(output,label.float())\n",
    "                else:\n",
    "                    loss = loss_function(output,label)\n",
    "\n",
    "                \n",
    "                validation_loss += loss.item()*inputs.size(0)\n",
    "                if BINARY:\n",
    "                    output[output<0.5] = 0\n",
    "                    output[output>=0.5] = 1\n",
    "                    correct = (output == label).float().sum().item()\n",
    "                    total_acc_val += correct\n",
    "                else:\n",
    "                    correct = (output.argmax(dim=1) == label).sum().item()\n",
    "                    total_acc_val += correct\n",
    "                \n",
    "        # If the training is doing worse then a median set, stop training to save time\n",
    "        prune_check = total_acc_val/len(validation_set)       \n",
    "        trial.report(prune_check, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "          raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return total_acc_val/len(validation_set)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params):\n",
    "    bertconfig = BertConfig()\n",
    "    tokenizer2 = AutoTokenizer.from_pretrained(params['bert_model'])\n",
    "\n",
    "    bert2 = BertModel.from_pretrained(params['bert_model'])\n",
    "    \n",
    "    #Only want to train the additional layers at first,freezing pretrained\n",
    "    for param in bert2.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for idx,param in enumerate(bert2.encoder.layer):\n",
    "        if 1+idx>len(bert2.encoder.layer)-params['number_to_unfreeze']:\n",
    "            param.requires_grad = True\n",
    "        bert2.pooler.requires_grad = True\n",
    "\n",
    "\n",
    "    return bert_for_sarcasm(bert2,params['linear1'],params['linear2'],params['drop'],params['mod_type'],params['bert_model']),tokenizer2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for hyper-parameter testing\n",
    "def objective(trial):\n",
    "    # Set of hyper-parameters we are interested in analyzing\n",
    "    params = {\n",
    "        'lr':trial.suggest_categorical('lr',[1e-5,1e-4,1e-3]),\n",
    "        'linear1': trial.suggest_categorical('linear1',[256,512]),\n",
    "        'linear2': trial.suggest_categorical('linear2',[64,128]),\n",
    "        'drop': trial.suggest_categorical(\"drop\",[0,.1,.2]),\n",
    "        'batch_size': trial.suggest_categorical('batch_size',[32,64]),\n",
    "        'schedule': trial.suggest_categorical('schedule',['none','cosine']), #linear\n",
    "        'bert_model': trial.suggest_categorical('bert_model',['bert-base-uncased']), #bert-large-uncased\n",
    "        'mod_type': trial.suggest_categorical('mod_type',['binary']), # binary or multi\n",
    "        'number_to_unfreeze': trial.suggest_categorical('number_to_unfreeze',[0,1,2,4,6,12])\n",
    "    }\n",
    "    \n",
    "    \n",
    "    model,tokenizer = build_model(params)\n",
    "    \n",
    "    accuracy = train_bert(model,params,trial,tokenizer)\n",
    "    \n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRkBO-CHdJkx"
   },
   "outputs": [],
   "source": [
    "def optimal_values(study):\n",
    "    # Return the optimal values from the hyper-parameter testing\n",
    "    \n",
    "    best_trial = study.best_trial\n",
    "    best_parameters = best_trial.params\n",
    "    return best_parameters\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9thujkkndLAL"
   },
   "outputs": [],
   "source": [
    "# Training after hyper-parameter testing\n",
    "def train_optimized_bert(model,params,tokenizer,Epochs):\n",
    "   \n",
    "    model.to(device)\n",
    "    #Set max length for the padding/clipping\n",
    "    max_length = 35\n",
    "    #Create tokenized training, validation, and test splits\n",
    "\n",
    "    training_tokens = tokenizer.batch_encode_plus(train_headlines.tolist(),max_length = max_length,padding = True,truncation = True)\n",
    "    validation_tokens = tokenizer.batch_encode_plus(validation_headlines.tolist(),max_length = max_length,padding = True,truncation = True)\n",
    "    test_tokens = tokenizer.batch_encode_plus(test_headlines.tolist(),max_length = max_length,padding= True,truncation = True)\n",
    "\n",
    "    #Stacking the inputs as tensors for use in the BERT model\n",
    "\n",
    "    training_set = TensorDataset(torch.tensor(training_tokens['input_ids']),torch.tensor(training_tokens['attention_mask']),torch.tensor(train_label.tolist()))\n",
    "    validation_set = TensorDataset(torch.tensor(validation_tokens['input_ids']),torch.tensor(validation_tokens['attention_mask']),torch.tensor(validation_label.tolist()))\n",
    "    test_set = TensorDataset(torch.tensor(test_tokens['input_ids']),torch.tensor(test_tokens['attention_mask']),torch.tensor(test_label.tolist()))\n",
    "\n",
    "    # Data loaders \n",
    "    trainloader = DataLoader(training_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "    validationloader = DataLoader(validation_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "    testloader = DataLoader(test_set, batch_size = params['batch_size'],num_workers=2,shuffle = True)\n",
    "\n",
    "\n",
    "    optimizer = AdamW(model.parameters(),lr = params[\"lr\"],eps = 1e-6)\n",
    "    NO_SCHEDULER = False\n",
    "    if params['schedule'] == \"linear\":\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 2,num_training_steps = len(trainloader)*Epochs)\n",
    "    elif params['schedule'] == 'cosine':\n",
    "        scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer,num_warmup_steps = 2, num_training_steps = len(trainloader)*Epochs)\n",
    "    else:\n",
    "        NO_SCHEDULER = True\n",
    "        \n",
    "        \n",
    "    if params['mod_type'] == 'binary':\n",
    "        loss_function = nn.BCELoss()\n",
    "        BINARY = True\n",
    "    else:\n",
    "        loss_function = nn.NLLLoss()\n",
    "        BINARY = False\n",
    "        \n",
    "    # For checking early stop criteria\n",
    "    min_validation_loss = np.inf\n",
    "    patience = 3\n",
    "    stop_number = 0\n",
    "    epoch_count = 0\n",
    "    running_validation_loss = []\n",
    "    running_training_loss = []\n",
    "    validation_acc = []\n",
    "    training_acc = []\n",
    "    \n",
    "    last_loss = np.inf\n",
    "    for epoch in range(1, Epochs+1):\n",
    "        epoch_count+=1\n",
    "        print(epoch_count)\n",
    "        model.train()\n",
    "        training_loss = 0 \n",
    "\n",
    "        train_correct = 0 \n",
    "        total_acc_train = 0\n",
    "        for idx, (inputs,attention_mask,label) in enumerate(tqdm(trainloader,total = len(trainloader))):\n",
    "\n",
    "            inputs,attention_mask,label = inputs.to(device),attention_mask.to(device),label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(inputs,attention_mask)\n",
    "            \n",
    "            if BINARY:\n",
    "                output = torch.flatten(output)\n",
    "                loss = loss_function(output,label.float())\n",
    "            else:\n",
    "                loss = loss_function(output,label)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss +=loss.item()*inputs.size(0)\n",
    "\n",
    "            \n",
    "            if BINARY:\n",
    "                output[output<0.5] = 0\n",
    "                output[output>=0.5] = 1\n",
    "                train_correct = (output == label).float().sum().item()\n",
    "                total_acc_train += train_correct\n",
    "            else:\n",
    "                train_correct = (output.argmax(dim=1) == label).sum().item()\n",
    "                total_acc_train += train_correct\n",
    "\n",
    "        if NO_SCHEDULER == False:\n",
    "            scheduler.step()\n",
    "\n",
    "    \n",
    "        validation_loss = 0\n",
    "\n",
    "        total_acc_val = 0\n",
    "        val_correct = 0 \n",
    "      \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (inputs,attention_mask,label) in enumerate(tqdm(validationloader,total = len(validationloader))):\n",
    "                inputs,attention_mask,label = inputs.to(device),attention_mask.to(device),label.to(device)\n",
    "\n",
    "                output = model(inputs,attention_mask)\n",
    "                \n",
    "                if BINARY:\n",
    "                    output = torch.flatten(output)\n",
    "                    loss = loss_function(output,label.float())\n",
    "                else:\n",
    "                    loss = loss_function(output,label)\n",
    "                    \n",
    "                validation_loss += loss.item()*inputs.size(0)\n",
    "                \n",
    "                if BINARY:\n",
    "                    output[output<0.5] = 0\n",
    "                    output[output>=0.5] = 1\n",
    "                    val_correct = (output == label).float().sum().item()\n",
    "                    total_acc_val += val_correct\n",
    "                else:\n",
    "                    val_correct = (output.argmax(dim=1) == label).sum().item()\n",
    "                    total_acc_val += val_correct\n",
    "\n",
    "        #Early Stopping Criteria\n",
    "    \n",
    "        if validation_loss>= last_loss:\n",
    "            stop_number+=1\n",
    "            if stop_number >= patience:\n",
    "                return model,running_training_loss,training_acc,running_validation_loss,validation_acc,epoch_count,testloader\n",
    "        else:\n",
    "            stop_number = 0\n",
    "            if validation_loss< min_validation_loss:\n",
    "                min_validation_loss = validation_loss\n",
    "                #Save the best performing model parameters \n",
    "                torch.save(model.state_dict(), MODEL_PATH)\n",
    "        last_loss = validation_loss\n",
    "            \n",
    "        if validation_loss>= min_validation_loss:\n",
    "            stop_number+=1\n",
    "            if stop_number >patience:\n",
    "                return model,running_training_loss,training_acc,running_validation_loss,validation_acc,epoch_count,testloader\n",
    "        else:\n",
    "            min_validation_loss = validation_loss\n",
    "            stop_number = 0\n",
    "            #Save the best performing model parameters \n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "\n",
    "        # For graphing training and testing loss, accuracy\n",
    "        running_validation_loss.append(validation_loss/len(validation_set))\n",
    "        running_training_loss.append(training_loss/len(training_set))\n",
    "\n",
    "        validation_acc.append(total_acc_val/len(validation_set))\n",
    "        training_acc.append(total_acc_train/len(training_set))\n",
    "\n",
    "    return model,running_training_loss,training_acc,running_validation_loss,validation_acc,epoch_count,testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzPYLhl_dPBu"
   },
   "outputs": [],
   "source": [
    "# Final Model Testing\n",
    "def test_bert(model,testloader):\n",
    "    correct = []\n",
    "    final_pred = []\n",
    "    final_lab = []\n",
    "    model.eval()\n",
    "    \n",
    "    # For selecting correct loss function, properly working with the outputs\n",
    "    if model.mod_type == 'binary':\n",
    "        BINARY = True\n",
    "    else:\n",
    "        BINARY = False\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs,attention_mask,label) in enumerate(tqdm(testloader,total = len(testloader))):\n",
    "            inputs,attention_mask,label = inputs.to(device),attention_mask.to(device), label.to(device)\n",
    "            output = model(inputs,attention_mask).cpu()\n",
    "            if BINARY:\n",
    "                output = torch.flatten(output)\n",
    "                output[output<0.5] = 0\n",
    "                output[output>=0.5] = 1\n",
    "                final_lab.extend(label.cpu().numpy())\n",
    "                final_pred.extend(output.numpy())\n",
    "            else:\n",
    "                preds = output.data.max(1, keepdim=True)[1].squeeze(1).numpy()\n",
    "\n",
    "                l = label.cpu().numpy()\n",
    "                comp = l == preds\n",
    "                final_lab.extend(l)\n",
    "                final_pred.extend(preds)\n",
    "\n",
    "    return final_lab,final_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running all functions to find and evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AZB4Bgad-d3"
   },
   "outputs": [],
   "source": [
    "# Create and train final model \n",
    "\n",
    "# Find Best Hyper-Parameters\n",
    "Epochs = 150 # Training epochs for the best performing model from hyper-parameter testing\n",
    "n_trials = 150 # Number of combinations of hyper-parameters to test \n",
    "n_jobs = 1 # Number of parallel trials \n",
    "study = optuna.create_study(direction=\"maximize\",\n",
    "                            sampler=optuna.samplers.TPESampler(),\n",
    "                            pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_jobs = n_jobs,n_trials=n_trials,show_progress_bar = True)\n",
    "\n",
    "# Plots to visualize the hyper-paremeter search \n",
    "plot_optimization_history(study);\n",
    "plot_param_importances(study);\n",
    "\n",
    "# Getting best parameters to train final model\n",
    "\n",
    "best_parameters = optimal_values(study)\n",
    "print('Best Values:')\n",
    "for key, value in best_parameters.items():\n",
    "    print(key, ' : ', value)\n",
    "final_model,tokenizer = build_model(best_parameters)\n",
    "\n",
    "# Training the final model \n",
    "trained_final_model,train_loss,train_acc,val_loss,val_acc,epoch_count,testloader = train_optimized_bert(final_model,best_parameters,tokenizer,Epochs)\n",
    "\n",
    "# Training and Validation Loss Plots\n",
    "plt.plot(train_loss,'g',label = 'Training Loss')\n",
    "plt.plot(val_loss,'r',label = 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Training and Validation Accuracy Plots\n",
    "plt.plot(val_acc,'g',label = 'Training Accuracy')\n",
    "plt.plot(train_acc,'r',label = 'Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Testing Final Model\n",
    "final_lab,final_pred = test_bert(trained_final_model,testloader)\n",
    "\n",
    "# Visualizing the results\n",
    "conf_mat = confusion_matrix(final_lab, final_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "plt.title('Confusion Matrix For Sarcasm_BERT')\n",
    "disp.plot(ax = ax)\n",
    "\n",
    "r_words = [\"Sarcastic\",\"Not Sarcastic\"]\n",
    "class_report = classification_report(final_lab,final_pred,target_names =r_words)\n",
    "print('\\033[1m'+'Precision, Recall and Accuracy for Headline Data:\\n')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7298tFreAKc"
   },
   "outputs": [],
   "source": [
    "# Looking at the tokenizer and its output\n",
    "\n",
    "new = tokenizer(\"Smartest Man In World Dead After Papercut\",return_tensors=\"pt\")\n",
    "new.to(device)\n",
    "print(new)\n",
    "outputs = trained_final_model(new['input_ids'],new['attention_mask']).detach().cpu()\n",
    "print(np.exp(outputs))\n",
    "a = outputs.data.max(1, keepdim=True)[1].squeeze(1).numpy()\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCoFPKMPeDTv"
   },
   "source": [
    "## Original No Hyper-Paremeter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gwuZp-1eI3x"
   },
   "outputs": [],
   "source": [
    "#Getting the BERT outputs for use with other downstream model implementations \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNGL92RheMG4"
   },
   "outputs": [],
   "source": [
    "#Reading in the data\n",
    "df = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\",lines = True)\n",
    "df = df.rename(columns={'is_sarcastic': 'label'})\n",
    "df = df.drop('article_link', 1)\n",
    "df.head()\n",
    "\n",
    "#splits for training test validation\n",
    "\n",
    "train_headlines, temporary_text, train_label, temporary_label = train_test_split(df['headline'], df['label'], \n",
    "                                                                    random_state=200, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "validation_headlines, test_headlines, validation_label, test_label = train_test_split(temporary_text, temporary_label, \n",
    "                                                                    random_state=200, \n",
    "                                                                    test_size=0.5, \n",
    "                                                                    stratify=temporary_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLEBZcr6eNLz"
   },
   "outputs": [],
   "source": [
    "#initialize the BERT \n",
    "\n",
    "bertconfig = BertConfig()\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "bert2 = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "#Only want to train the additional layers at first,freezing pretrained\n",
    "for param in bert2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create a model which takes output from BERT and run through new layers for classification\n",
    "\n",
    "\n",
    "class bert_for_sarcasm(nn.Module):\n",
    "\n",
    "    def __init__(self,input_model):\n",
    "        super(bert_for_sarcasm,self).__init__()\n",
    "        \n",
    "        self.input_model = input_model\n",
    "        \n",
    "        self.linear = nn.Linear(768,256)\n",
    "        \n",
    "        self.linear2 = nn.Linear(256,128)\n",
    "        \n",
    "        self.linear3 = nn.Linear(128,2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.log = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self,input_values,attention_mask):\n",
    "   \n",
    "        _,output = self.input_model(input_values, attention_mask=attention_mask).values()\n",
    "        \n",
    "        output = self.linear(output)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        output = self.relu(output)\n",
    "        \n",
    "        output = self.linear2(output)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        output = self.relu(output)\n",
    "        \n",
    "        output = self.linear3(output)\n",
    "        \n",
    "        output = self.log(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "#Put updated sarcasm model on GPU\n",
    "sarcasm_model = bert_for_sarcasm(bert2)\n",
    "# sarcasm_model.to(device)\n",
    "\n",
    "for name,child in sarcasm_model.named_children():\n",
    "    if name == input_model:\n",
    "        print('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,child in bert2.named_children():\n",
    "    print(name)\n",
    "\n",
    "for idx,param in enumerate(bert2.encoder.layer):\n",
    "    if 1+idx>9:\n",
    "        param.requires_grad = True\n",
    "#         print(param)\n",
    "    \n",
    "print(bert2.encoder.layer[9].requires_grad)\n",
    "# for param in bert2.encoder.layer[0]:\n",
    "#     if param.requires_grad == True:\n",
    "#         print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woDUMijhePjI"
   },
   "outputs": [],
   "source": [
    "#Set max length for the padding/clipping\n",
    "count = df['headline'].str.split().str.len()\n",
    "count.describe()\n",
    "\n",
    "max_length = 35\n",
    "#Create tokenized training, validation, and test splits\n",
    "\n",
    "training_tokens = tokenizer2.batch_encode_plus(train_headlines.tolist(),max_length = max_length,padding = True,truncation = True)\n",
    "validation_tokens = tokenizer2.batch_encode_plus(validation_headlines.tolist(),max_length = max_length,padding = True,truncation = True)\n",
    "test_tokens = tokenizer2.batch_encode_plus(test_headlines.tolist(),max_length = max_length,padding= True,truncation = True)\n",
    "\n",
    "#Stacking the inputs as tensors for use in the BERT model\n",
    "\n",
    "training_set = TensorDataset(torch.tensor(training_tokens['input_ids']),torch.tensor(training_tokens['attention_mask']),torch.tensor(train_label.tolist()))\n",
    "validation_set = TensorDataset(torch.tensor(validation_tokens['input_ids']),torch.tensor(validation_tokens['attention_mask']),torch.tensor(validation_label.tolist()))\n",
    "test_set = TensorDataset(torch.tensor(test_tokens['input_ids']),torch.tensor(test_tokens['attention_mask']),torch.tensor(test_label.tolist()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1dKUnOJeRG3"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Dataloaders for the sets\n",
    "\n",
    "trainloader = DataLoader(training_set, batch_size = batch_size,num_workers=2,shuffle = True)\n",
    "validationloader = DataLoader(validation_set, batch_size = batch_size,num_workers=2,shuffle = True)\n",
    "testloader = DataLoader(test_set, batch_size = batch_size,num_workers=2,shuffle = True)\n",
    "\n",
    "#Loss function (standard in the BERT documentation is MSELoss)\n",
    "loss_function = nn.NLLLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liZDlECbeRWf"
   },
   "outputs": [],
   "source": [
    "#Training sarcasm bert\n",
    "Epochs = 150\n",
    "\n",
    "running_training_loss = []\n",
    "running_validation_loss = []\n",
    "\n",
    "#optimizer and scheduler for learning rate\n",
    "optimizer = AdamW(sarcasm_model.parameters(),lr = 1e-4,eps = 1e-6)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 2,num_training_steps = len(trainloader)*Epochs)\n",
    "\n",
    "min_validation_loss = np.inf\n",
    "\n",
    "for epoch in range(1, Epochs+1):\n",
    "    print('Epoch: ',epoch)\n",
    "    sarcasm_model.train()\n",
    "    training_loss = 0 \n",
    "\n",
    "    for idx, (inputs,attention_mask,label) in enumerate(tqdm(trainloader,total = len(trainloader))):\n",
    "\n",
    "        inputs,attention_mask,label = inputs.to(device),attention_mask.to(device),label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = sarcasm_model(inputs,attention_mask)\n",
    "\n",
    "        loss = loss_function(output,label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        training_loss +=loss.item()\n",
    "    \n",
    "    \n",
    "    \n",
    "    validation_loss = 0\n",
    "    sarcasm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs,attention_mask,label) in enumerate(tqdm(validationloader,total = len(validationloader))):\n",
    "            inputs,attention_mask,label = inputs.to(device),attention_mask.to(device),label.to(device)\n",
    "\n",
    "            output = sarcasm_model(inputs,attention_mask)\n",
    "            loss = loss_function(output,label)\n",
    "            validation_loss += loss.item()\n",
    "\n",
    "        # For graphs\n",
    "        running_validation_loss.append(validation_loss/len(validationloader))\n",
    "        running_training_loss.append(training_loss/len(trainloader))\n",
    "\n",
    "        #Store the best performing model\n",
    "        if validation_loss<min_validation_loss:\n",
    "            min_validation_loss = validation_loss\n",
    "            #Save this model \n",
    "            torch.save(sarcasm_model.state_dict(), MODEL_PATH)\n",
    "\n",
    "    print('Epoch',epoch, '\\t\\t Training Loss:',training_loss / len(trainloader), '\\t\\t', 'Validation Loss:', validation_loss / len(validationloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kk3lSRmCeUTU"
   },
   "outputs": [],
   "source": [
    "# Load best model \n",
    "best_model = bert_for_sarcasm(bert2)\n",
    "best_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "best_model.to(device)\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeMtWxpAeXE7"
   },
   "outputs": [],
   "source": [
    "correct = []\n",
    "final_pred = []\n",
    "final_lab = []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for idx, (inputs,attention_mask,label) in enumerate(tqdm(testloader,total = len(testloader))):\n",
    "        inputs,attention_mask,label = inputs.to(device),attention_mask.to(device), label.to(device)\n",
    "        output = best_model(inputs,attention_mask).cpu()\n",
    "        preds = output.data.max(1, keepdim=True)[1].squeeze(1).numpy()\n",
    "\n",
    "        l = label.cpu().numpy()\n",
    "        comp = l == preds\n",
    "        final_lab.extend(l)\n",
    "        final_pred.extend(preds)\n",
    "        for i in range(l.size):\n",
    "          if comp[i] == True:\n",
    "            correct.append(1)\n",
    "          else:\n",
    "            correct.append(0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kO5HOaEeYmJ"
   },
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "conf_mat = confusion_matrix(final_lab, final_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "plt.title('Confusion Matrix For Sarcasm_BERT')\n",
    "disp.plot(ax = ax)\n",
    "\n",
    "r_words = [\"Sarcastic\",\"Not Sarcastic\"]\n",
    "class_report = classification_report(final_lab,final_pred,target_names =r_words)\n",
    "print('\\033[1m'+'Precision, Recall and Accuracy for Headline Data:\\n')\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Headlines_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
